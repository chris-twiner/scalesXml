{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Scales XML","text":""},{"location":"#060-m5","title":"0.6.0-M5","text":"Coverage<p> Statement 77.86 Branch 74.01 </p> <p>Scales XML is an alternative XML library for Scala, its design started with the question - what if the structure of XML was separated from its contents?.</p> <p>The answer for XML tends naturally to trees and zippers, enabling a combined model for both XML Tree handling and XML Event handling.  This allows opportunities for saving memory usage and increasing performance.</p> <p>The design aims of Scales Xml also target correctness first, an Iteratee based processing for Pull, an XPath like syntax for querying and manipulation and deep support for JAXP.</p> <p>The main focus areas are</p> <ul> <li>Correctness</li> <li>Simplified and consistent model - shared between push and pull</li> <li>Allowing full re-use of the data model - QNames, Elems etc all reusable </li> <li>Fast Internal XPath Api</li> <li>Full XPath1.0 String evaluation support via Jaxen</li> <li>Iteratee based xml Pull handling - you choose what, when and how to process </li> <li>Non-blocking IO xml Pull processing via Aalto </li> <li>High Level of JAXP Integration - Validation, TrAX and Serialisation (when needed)</li> <li>Performance - fast with low memory usage</li> </ul>"},{"location":"Accessing_and_Querying_Data/StringXPaths/","title":"XPath 1.0 String Evaluation","text":"<p>The embedded XPath DSL provides a very flexible and performant way to query xml.  However, being an embedded DSL, it has the negative of being wed to the compilation cycle.  For those seeking a more direct XPath string parsing based experience Scales provides access via the Jaxen project.</p> <p>The scales-jaxen project is a sub project and must be included separately as a library dependency.</p>"},{"location":"Accessing_and_Querying_Data/StringXPaths/#how-to-use","title":"How To Use","text":"<p>The following dependency must be used (instead of scales-xml):</p> <pre><code>  \"scales\" %% \"scales-jaxen\" % \"0.3\" // or 0.4 for a Scalaz 6.0.4 dependency\n</code></pre> <p>After importing the package use the ScalesXPath constructor with either a map of prefix to uri, or a list of PrefixedNamespaces (similar to Elem construction):</p> <pre><code>  import scales.xml.jaxen._\n\n// prefix mappings are needed for context\nval aPath = ScalesXPath(\"//*[1]\", Map(\"pre\" -&gt; \"urn:prefix\"))\n// the type annotation is for illustrative reasons only :-&gt;\nval result : Iterable[Either[AttributePath, XmlPath]] = aPath.evaluate(anXmlPath)\n\n// direct XPath results use get\nval anotherPath = ScalesXPath(\"string(//*[1])\", Map(\"pre\" -&gt; \"urn:prefix\"))\n// This uses casts to retrieve values, it can throw.\nval string = anotherPath.get[String](anXmlPath)\n</code></pre> <p>Results are always returned in Document order.</p> <p>Rather than dealing with an Either for results, when the developer probably knows what type he wants, xmlPaths and attributePaths can be used:</p> <pre><code>  val ns = Namespace(\"test:uri\")\nval nsa = Namespace(\"test:uri:attribs\")\nval nsp = nsa.prefixed(\"pre\")\n\nval builder = ns(\"Elem\") /@ (nsa(\"pre\", \"attr1\") -&gt; \"val1\",\n\"attr2\" -&gt; \"val2\",\nnsp(\"attr3\") -&gt; \"val3\") /(\nns(\"Child\"),\n\"Mixed Content\",\nns(\"Child2\") /( ns(\"Subchild\") ~&gt; \"text\" )\n)\n\nval elems = ScalesXPath(\"//*\")\nelems.xmlPaths(path).map(qname(_)) // List(Elem, Child, Child2, Subchild)\nelems.attributePaths(path).map(qname(_)) // List()\n\nval attribs = ScalesXPath(\"//@*\")\nattribs.xmlPaths(path).map(qname(_)) // List()\nattribs.attributePaths(path).map(qname(_)) // List(pre:attr3, attr2, pre:attr1)\n</code></pre> <p>As a shortcut to ignore namespaces (instead of using prefixes) use:</p> <pre><code>  ScalesXPath(\"/html/body/p[2]/table[2]/tr/td/table/tr/td[1]/a/font\").withNameConversion(ScalesXPath.localOnly)\n</code></pre> <p>The function passed to withNameConversion is of type: </p> <pre><code>QName =&gt; QName$\n</code></pre> <p>allowing further mappings as needed.</p>"},{"location":"Accessing_and_Querying_Data/StringXPaths/#other-jaxen-tricks","title":"Other Jaxen Tricks","text":"<p>Jaxen provides various extensions to straight forward querying, including adding java extension functions.  If possible, of course, use the embedded DSL, if not ScalesXPath is a Jaxen XPath implementation, allowing calls to setFunctionContext, variableContext etc.</p>"},{"location":"Accessing_and_Querying_Data/XPathFunctions/","title":"XPath Functions","text":"<p>The XPath specs define a number of useful functions which are specific to XML, other string or number related functionality is provided by Scala itself and is not replicated by the XPath DSL.</p>"},{"location":"Accessing_and_Querying_Data/XPathFunctions/#organisation","title":"Organisation","text":"<p>The XPath Functions are organised into three main type classes:</p> <ol> <li>Names</li> <li>TextValue</li> <li>Boolean</li> </ol> <p>Names provides a type class for any type that can represent a QName:</p> <ul> <li>Attributes</li> <li>Elems</li> <li>XmlTrees</li> <li>XPaths (name of the first node, \"empty\" otherwise)</li> <li>QNames</li> </ul> <p>TextValue, representing everything that can produce a text value, has a similar base list:</p> <ul> <li>XmlTrees</li> <li>Attributes</li> <li>XmlItems</li> <li>XPaths (value of the first node)</li> </ul> <p>In general if any logical combination thereof is possible they are also supported (for example XmlPaths themselves)</p> <p>The boolean family of type class instances:</p> <ul> <li>XPaths (is it non-empty)</li> <li>Iterables (is it non-empty)</li> <li>String (length &gt; 0)</li> <li>Number (value &gt; 0) and of course</li> <li>Boolean</li> </ul>"},{"location":"Accessing_and_Querying_Data/XPathFunctions/#qname-functions","title":"QName Functions","text":"<p>The full list of functions is available here.</p> <p>Some examples:</p> <pre><code>  val attr : Attribute = \"attr\" -&gt; \"value\"\n\nqname(attr) // attr\npqName(attr) // {}attr\nnamespaceUri(attr) // \"\"\n\nval ns = Namespace(\"uri:namespace\")\nval pre = ns.prefixed(\"pre\")\n\nval prefixedAttr : Attribute = pre(\"prefixed\") -&gt; \"prefixed value\"\nqname(prefixedAttr) // pre:prefixed\npqName(prefixedAttr) // pre:{uri:namespace}prefixed\nnamespaceUri(prefixedAttr) // uri:namespace\n\nval elem = Elem(pre(\"prefixedElem\"))\nqname(elem) // pre:prefixedElem\npqName(elem) // pre:{uri:namespace}prefixedElem\nnamespaceUri(elem) // uri:namespace\n\nval tree = elem /( elem ~&gt; \"\\ndeep  value\\n\" )\n\npqName(tree) // pre:{uri:namespace}prefixedElem\n</code></pre> <p>Using the <code>name</code> function with a non QName XPath (e.g. an XmlItem) will result in an exception.</p>"},{"location":"Accessing_and_Querying_Data/XPathFunctions/#text-functions","title":"Text Functions","text":"<p>The full list of functions is available here.</p> <p>Some examples (using the above definitions):</p> <pre><code>  value(attr) // value\nvalue(prefixedAttr) // prefixed value\n\n// won't compile as there is no meaningful way to get an elems value\n// value(elem)\n\nvalue(tree.toTree) // \\ndeep  value\\n\nnormalizeSpace(tree) // deep value, but using type class directly\n</code></pre>"},{"location":"Accessing_and_Querying_Data/XPathFunctions/#boolean-function","title":"Boolean Function","text":"<pre><code>  boolean(\"\") // false\nboolean(\"value\") // true\n\nboolean(true) // true\n</code></pre>"},{"location":"Accessing_and_Querying_Data/XPaths/","title":"XPath Embedded DSL","text":"<p>The XML XPath specifications allows navigation of XML documents via a DSL that describes routes through a document using a combination of axe, steps and predicates.  It has a limited number of these abstractions but together they create a powerful direct, whilst remaining simple to use, querying language.</p> <p>Scales provides this power via both a traditional string based approach and an embedded DSL that leverages the power of Scalas syntactical flexibility to mimic the XPath syntax.</p> <p>The DSL uses the existing Scales abstractions to the full, and works via a zipper over the XmlTree itself.  Each navigation step through the tree creates new zippers and new paths through the tree.</p> <p>In every case possible (with the exception of the namespace:: axis) the range of behaviours closely follows the specification, like for like queries matching 100%.  Instead of matching on prefixes Scales uses fully qualified expanded QNames (qualifiedName in the QName Functions) to match against, not requiring a prefix context within which to evaluate.</p> <p>Internally, perhaps unsurprisingly, XPath is implemented as a combination of filter, map and flatMap.  When retrieving results (e.g. converting to an Iterable) the results are sorted into Document order, this can be expensive for large result sets (see Unsorted Results for alternatives).</p>"},{"location":"Accessing_and_Querying_Data/XPaths/#simple-usage-examples","title":"Simple Usage Examples","text":"<p>Given the following document:</p> <pre><code>  val ns = Namespace(\"test:uri\")\nval nsa = Namespace(\"test:uri:attribs\")\nval nsp = nsa.prefixed(\"pre\")\n\nval builder = ns(\"Elem\") /@ (nsa(\"pre\", \"attr1\") -&gt; \"val1\",\n\"attr2\" -&gt; \"val2\",\nnsp(\"attr3\") -&gt; \"val3\") /(\nns(\"Child\"),\n\"Mixed Content\",\nns(\"Child2\") /( ns(\"Subchild\") ~&gt; \"text\" )\n)\n</code></pre> <p>we can easily query for the Subchild:</p> <pre><code>  // top produces a Path from a Tree, in this case an XPath\nval path = top(builder)\n\nval res = path \\* ns(\"Child2\") \\* ns(\"Subchild\")\nres.size // 1\n\nstring(res) // text\nqname(res) // Subchild\n</code></pre>"},{"location":"Accessing_and_Querying_Data/XPaths/#xpath-crash-course","title":"XPath Crash Course","text":"<p>Scales Xml follows the XPath spec fairly closely and accordingly represents the concepts of context, location steps and axe, full details of which can be found in the XPath Standard.</p> <p>The context, which can be thought of as current \"place\" in the document, is represented by the following:</p> <ul> <li>a notional node - where we are in the document - an element, a text node, an attribute etc.</li> <li>the position - index within a context and the size of this context</li> </ul> <p>Location steps are a combination of axe, node test and predicates e.g. /*fred which represents the child axe, element node test and a predicate against a no-namespace local name of \"fred\".</p> <p>As the XPath adds more axe, steps and predicates the context changes, reducing or expanding possible matches as it develops.  Scales Xml's XPath DSL represents that context with the XPath class, where each operation on that class returns another immutable instance for the next context.</p> <p>As with XPath, Scales Xml predicates, axe and node tests can be chained with the current context (the self axe in XPath) always represented by the resulting Scales XPath object.  Only when the underlying results are used (for example by string or qname functions) do they leave the XPath object and get transformed into a, by default, ordered list of matching nodes.</p>"},{"location":"Accessing_and_Querying_Data/XPaths/#xpath-axe","title":"XPath Axe","text":"<p>Scales supports the complete useful XPath axe, each of which can be used against a given context (an instance of Scales XPath), for the full XPath axe details find the spec here:</p> <p>{|class=\"genTable\" !XPath Axis !Scales DSL !Details |- |ancestor||ancestor_::||All the parents of this context |- |ancestor-or-self||ancestor_or_self::||All the parents of this context and this node |- |attribute||*@||All the attributes for a given context, is often combined directly with a name |-</p> <p>|child||\\ or + to expand XmlItems||Children of this context. NB: \\ alone in Scales DSL simply removes the initialNode setting required by \\.  If the children should be expanded (e.g. to use .filter directly) then + will \"unpack\" the child nodes. |- |descendant||descendant_::||All children, and their children |- |descendant-or-self||descendant_or_self_::||This node and all descendants, also known as \\ |-</p> <p>|following||following_::||All nodes that follow this context in document order without child nodes of this context |- |following-sibling||following_sibling_::||All direct children of this contexts parent node that follow in document order. |- |parent||\\^||The parent context of this context.  For elements it represents the parent eleemnt and for attributes the containing element. |-</p> <p>|preceding||preceding_::||All nodes that precede this context in document order excluding the parent nodes |- |preceding-sibling||preceding_sibling_::||All previous children of the parent in the current context in document order. |- |self||The XPath object itself via '''.'''||The current context node within a document. |}</p> <p>A commonly used abbreviation not listed above is of course \\, which means descendant_or_self_::.  The difference being that \\ also supports possible eager evaluation and as per the spec the notion of [http://www.w3.org/TR/xpath20/#id-path-expressions \\ in the beginning expression].</p> <p>''NB Scales Embedded XPath DSL does not support the namespace axis - if you have a requirement for it then it can be looked at (please send an email to [mailto:scales-xml@googlegroups.com the mailing list] to discuss possible improvements)''</p>"},{"location":"Accessing_and_Querying_Data/XPaths/#node-tests","title":"Node Tests","text":"<p>Scales embedded XPath DSL views the majority of node tests as predicates</p> <p>{|class=\"genTable\" !XPath Node Test !Scales DSL !Details |- |node()||.+||Returns a new context for all the children below a given context |- |text()||.text||Returns a new context for all the text and cdata below a given context |- |comment()||.comment||Returns a new context for all the comments below a given context |}</p> <p>Scales XML also adds:</p> <ul> <li>.textOnly - filters out CData, just giving text nodes</li> <li>.cdata - provides CData nodes</li> <li>.pi - provides processing instructions</li> </ul>"},{"location":"Accessing_and_Querying_Data/XPaths/#predicates","title":"Predicates","text":"<p>There are three areas allowing for predicates within XPaths:</p> <ul> <li>Attributes</li> <li>Elements</li> <li>General</li> </ul> <p>The first two are special cased, as in the XPath spec, as they are the most heavily used predicates (using the above example document):</p> <pre><code>  // QName based match\nval attributeNamePredicates = path \\@ nsp(\"attr3\")\nstring(attributeNamePredicates) // \"val3\"\n// predicate based match\nval attributePredicates = path \\@ ( string(_) == \"val3\" )\nqualifiedName(attributePredicates) // {test:uri:attribs}attr3\n\n// Find child descendants that contain a Subchild \nval elemsWithASubchild = path \\\\* ( _ \\* ns(\"Subchild\"))\nstring(elemsWithASubchild) // text\nqualifiedName(elemsWithASubchild) // {test:uri}Child2\n</code></pre> <p>In each case the XmlPath (or AttributePath) is passed to the predicate with a number of shortcuts for the common QName based matches and positional matches for elements:</p> <pre><code>  val second = path \\*(2) // path \\* 2 is also valid but doesn't read like \\*[2]\nqname(second) // Child2\n</code></pre> <p>The developer can chose to ignore namespaces (not recommended) by using the : and :@ predicates instead (equivalent to string xpath /[local-name() = \"x\"]).</p>"},{"location":"Accessing_and_Querying_Data/XPaths/#predicate-construction","title":"Predicate Construction","text":"<p>All the predicates in Scales are built from two simple building blocks:</p> <ol> <li>XmlPath =&gt; Boolean - via the XPath.filter function</li> <li>AttributePath =&gt; Boolean - via the AttributeAxis.*@ function</li> </ol> <p>The various base node types and filters are based on these functions, for example the element predicate * is implemented as:</p> <pre><code>def *(pred : XmlPath =&gt; Boolean) : XPath[T] = filter(x =&gt; x.isItem == false &amp;&amp; pred(x))\n</code></pre> <p>In turn * can be seen as a combination of the \\ child step and the * predicate (via xflatMap) and is provided as syntactic sugar.</p> <p>Similarly text is implemented using filter.</p> <p>All of the standard set of predicates (and axis combinations) can be found in the  XPath ScalaDoc.  Clicking the right arrow for many of the functions will lead you to the Definition Classes docs and their code. </p>"},{"location":"Accessing_and_Querying_Data/XPaths/#chaining-predicates","title":"Chaining Predicates","text":"<p>Predicates can be chained on the context itself, i.e. the XPath object, for example:</p> <pre><code>val pathsCombinedPredicates =\nroot.\\*(ns(\"Child\")).\n*(_.\\@( nsp(\"attr3\") )) // context is still Child matches, but has additionally reduced it to only items with an attribute of attr3\n</code></pre> <p>This represents /root/*ns:Child[.@nsp:attr3] where the * Scales Xml element predicate allows matching on the self axis.  The same chaining is available on the attribute axis represented by the [./doc/scales/xml/xpath/AttributePaths.html AttributePaths] class.</p>"},{"location":"Accessing_and_Querying_Data/XPaths/#positional-predicates","title":"Positional Predicates","text":"<p>{|class=\"genTable\" !XPath Position Function !Scales DSL !Details |- |position()||pos_&lt;, pos_==, pos() and pos_&gt;||Functions to work against the current position within a context |- |last()||last_&lt;, last_== and last_&gt;||Functions that work against the size of a given context |- |position() == last()||pos_eq_last||Take the last item in a context |}</p> <p>These, more difficult to model, positional tests can be leveraged the same way as position() and last() can be in XPath.</p> <p>So, for example:</p> <pre><code>  // /*[position() = last()]\nval theLast = path.\\.pos_eq_last\nqname(theLast) // Elem\n\n// //*[position() = last()]\nval allLasts = path.\\\\*.pos_eq_last\nallLasts map(qname(_)) // List(Elem, Child2, Subchild)\n\n// all elems with more than one child\n// //*[ ./*[last() &gt; 1]]\nval moreThanOne = path.\\\\*( _.\\*.last_&gt;(1) )\nqname(moreThanOne) // Elem\n\n// all elems that aren't the first child\n// //*[ position() &gt; 1]\nval notFirst = path.\\\\*.pos_&gt;(1)\nqname(notFirst) // Child2\n</code></pre>"},{"location":"Accessing_and_Querying_Data/XPaths/#direct-filtering","title":"Direct Filtering","text":"<p>The xflatMap, xmap, xfilter and filter methods allow extra predicate usage where the existing XPath 1.0 functions don't suffice.</p> <p>The filter method accepts a simple XmlPath =&gt; Boolean, whereas the other varieties work on the matching sets themselves.</p> <p>It is not recommended to use these functions for general use as they primarily exist for internal re-use.</p>"},{"location":"Accessing_and_Querying_Data/XPaths/#unsorted-results-and-views","title":"Unsorted Results and Views","text":"<p>In order to meet XPath expected usage results are sorted in Document order and checked for duplicates.  If this is not necessary - but speed of matching over a result set is (for example lazy querying over a large set) - then the raw functions (either raw or rawLazy) are good choices.</p> <p>The viewed function however uses views as its default type and may help add further lazy evaluation.  Whilst tests have shown lazy evaluation takes place its worth profiling your application to see if it actually impacts performance in an expected fashion.</p> <p>See the XmlPaths trait for more information.</p>"},{"location":"Advanced/Technical_Details/OptimisationDetails/","title":"Scales Xml Optimisation Details","text":""},{"location":"Advanced/Technical_Details/OptimisationDetails/#immutablearrayproxy","title":"ImmutableArrayProxy","text":"<p>In order to reduce memory consumption Scales uses an abstraction over array like structures - ImmutableArrayProxy.  Vector is appropriate for large structures (&gt; 30 children) but inappropriate for smaller collections, taking many Mb of unnecessary memory usage.</p> <p>The same is true of a simple immutable array, the costs are too high for items less than 4 in size.</p> <p>As such Scales provides a One, Two and Three Seq, an ImmutableArray for less than 32 and a Vector wrapper for greater than 32.  There is also ImmutableArrayAll, which reduces offset information to further reduce memory usage.</p> <p>The builder itself is also optimised to allocate as little as possible and allow for re-use in the common case.</p>"},{"location":"Advanced/Technical_Details/OptimisationDetails/#eitherlike","title":"EitherLike","text":"<p>A simple concession to memory performance (and CPU performance) was the replacement of Either as a container and the creating of EitherLike.  EitherLike has the similar properties but is a trait applied to classes, fold and projections are still present but the memory usage from the level of indirection is removed.  Tests showed that 10-15% of the memory usage was held purely by the Either ADT, and performance was around 4-5% impact across the board due to the one level of indirection.</p> <p>EitherLike is currently not used for pull parsing due to Scalas / JVMs understandable erasure limitation of inheriting twice with different type parameters.</p>"},{"location":"Advanced/Technical_Details/OptimisationDetails/#treeoptimisation","title":"TreeOptimisation","text":"<p>The TreeOptimisation trait provides a simple way to mix in optimisations on Tree, see the docs and source for example implementations (QNameTreeOptimisation and QNameElemTreeOptimisation).</p> <p>The base Tree type is itself (as of 0.3) just an interface, allowing reduced memory usage in common cases (eg. repeated name value style elements) and a simple xml object conversion approach, where children may be lazily mapped.</p> <p>The ParsingPerformance tests also demonstrate the possibility to optimise away the element itself if a given document often repeats element content.</p> <p>When an optimised tree is modified (via copy) then it may still be further optimised or default to a normal Tree when no simple optimisation is possible.</p>"},{"location":"Advanced/Technical_Details/OptimisationDetails/#qname-and-elem-memory-usage","title":"QName and Elem Memory Usage","text":"<p>The QName and Elem structures are optimised to only keep references to items that are needed.  NoNamespaceQName will only have a single data member reference to the local name and UnprefixedQName has no prefixed stored.</p> <p>Elem is more interesting, given it has 4 relevant states, but takes the same approach.  If the attributes are empty but there are namespaces upon creation then the resulting Elem (NoAttribsElem) will not contain the reference.</p> <p>These simple optimisations positively affect memory usage considerably for large documents.</p>"},{"location":"Advanced/Technical_Details/OptimisationDetails/#treeproxies-and-builders","title":"TreeProxies and Builders","text":"<p>The Scales XmlParser infrastructure attempts to cache builders at each level of the tree.  If there are more than 3 children at any given element then the underlying builder (VectorBuilder / Pointer or ImmutableArray) cannot be re-used.</p> <p>The vast majority of XML will typically end at the leafs with an elem that has only one logical text node, the builders generating these leaves can be re-used.</p> <p>This level based builder caching and the heavily inlined ImmutableArrayProxy builders and TreeProxies together result in somewhat non idiomatic code but increases performance by 5-8%.</p>"},{"location":"Advanced/Technical_Details/Serialization/","title":"Serialising - Nitty Gritty","text":"<p>While Serialising provides a high-level overview of serializing in Scales, this section gets into the specifics of how its implemented and compatibility issues.</p> <p>Scales attempts the following:</p> <ol> <li>Work around a number of bugs and behavioural differences with the various LSSerializer implementations</li> <li>Stop as soon as possible with usable error messages - and give the user the tools to deal with that situation</li> <li>Correctness checking with both XmlVersion and CData handling along with encoding and markup generation</li> <li>Only perform serialisation encoding checks once</li> <li>Correctly re-use Charset encodings</li> <li>Allow plugable Serializers and sensible base implementations - if you don't like the way its working you can enhance it</li> </ol>"},{"location":"Advanced/Technical_Details/Serialization/#encoding","title":"Encoding","text":""},{"location":"Advanced/Technical_Details/Serialization/#xml-names","title":"XML Names","text":"<p>When serializing XML there are two traditional problems with inter-operation between creator and reader:</p> <ul> <li>Characterset of stream</li> <li>Encoding of document</li> </ul> <p>The xml parsers themselves should handle the former (i.e. via BOM and declarations etc), but the latter has more to do with the writing of the document itself.</p> <p>XML 1.0 allows the use of a large enough range of unicode names that umlauts are valid but the encoding might not be:</p> <pre><code>  &lt;?xml version=\"1.0\" encoding=\"US-ASCII\"?&gt;\n&lt;anr\u00fcchig/&gt;\n</code></pre> <p>This document is itself not valid, as the \u00fc in the markup cannot be represented by US-ASCII.</p> <p>The default LSSerializerSerializerFactory provides an implementation of the encF function which abstracts away this issue.  For a given character set it attempts to encode the string replying an Option[Throwable], with None indicating that it can be serialized with that encoding.  Each serialized QName has its parts checked against the shared global cache, to reduce costs in creating encoders and their use.</p> <p>A LSSerializerNoCacheFactory can be used if the caching behaviour is not desirable.</p>"},{"location":"Advanced/Technical_Details/Serialization/#text-data","title":"Text Data","text":"<p>All normal character data serialized by the LSSerializer instances will be safe across encodings, as per the spec they will be escaped as character references.  Which actual escaping used (hex or plain numeric) depends on the underlying JAXP implementation.</p>"},{"location":"Advanced/Technical_Details/Serialization/#other-markup-character-data","title":"Other Markup Character Data","text":"<p>CData, Comments and PI cannot have character references within their content.  As such they behave similarly to the encoding of XML Names, with respective exceptions of CDataCannotBeEncoded, CommentCannotBeEncoded and PICannotBeEncoded.</p> <p>CData deserves a special mention as many libraries (including the LS spec that Scales leverages) add splitting of cdata to allow extra character encodings.  In part due to the incompatible/incomplete jaxp implementation approaches Scales takes a simple design decision - either the CData can be serialised or not.</p> <p>Developers are free to customise this approach or indeed translate CData to Text wherever recipient systems will accept it.</p>"},{"location":"Advanced/Technical_Details/Serialization/#creating-a-serializerfactory","title":"Creating a SerializerFactory","text":"<p>It is advised to use the default factory wherever possible, however the LSSerializerBase and LSSerializer traits provides a useful extension point.  The LSSerializerFactoryXHTML shows an example of how it can be extended.</p> <p>The interface for SerializerFactory defines a single function:</p> <pre><code>trait SerializerFactory {\ndef apply[R](thunk: Serializer =&gt; R)(data: SerializerData): R\n}\n</code></pre> <p>The serialisation itself is performed in the context of thunk, where thunk accepts a Serializer.  The serializer itself contains a very small interface, with only one quirk:</p> <pre><code>  path: List[QName]\n</code></pre> <p>this allows even the Serializer to make assumptions about the structure based on its XPath (the same structure to the pull parsing onQName function).  In the case of element starting (emptyElement/startElement) the parameters are calculated by the serialize function itself.  This means that whilst the Serializer instance is free to choose how to serializer it is freed from making decisions on what attributes or namespaces or default namespaces are correctly defined for that scope.</p> <p>Overriding startElement or emptyElement would be the ideal place for applications requiring attributes be ordered.</p>"},{"location":"Advanced/XML_Equality/EqualityBasics/","title":"XML Equality Basics","text":"<p>The Scales Xml equality framework aims to help with both testing applications (similar to XmlUnit) that use Scales and also for runtime comparison activities, e.g. if an element has this attribute with this value do X.</p> <p>The Scales equality framework does not throw, but returns information allowing decisions to be made.  In the case of <code>===</code> a simple boolean is returned, in the case of <code>compare</code> a full ADT and path can be returned diagnosing the first difference found.</p> <p>The <code>compare</code> function is used by the Equal instances and is documented here.</p> <p>NB Scala 2.8.x support for the Equality framework is experimental.  Importing FromEqualsImplicit._ enables the use of === from Scalaz.  Unfortunately due to 2.8.x compiler issues the implicit resolution does not correctly function and may cause compiler crashes. </p>"},{"location":"Advanced/XML_Equality/EqualityBasics/#how-to-use","title":"How To Use","text":"<p>Scales Xml Equality leverages two type classes, XmlComparison and the Scalaz Equal typeclass to provide comparison via a simple === .  As such Scalaz must be imported (best after Scales imports to avoid Tree import issues):</p> <pre><code>  import scalaz._\nimport Scalaz._\n</code></pre> <p>Testing equality is therefore as simple as:</p> <pre><code>  val t1 = Text(\"fred\")\nval t2 = Text(\"fred\")\n\nassertTrue(\"t1 == t2\", t1 == t2) // equals\nassertTrue(\"t1 === t2\", t1 === t2) // Scalaz Equal type class\n\nassertTrue(\"t1 compare t2\", compare(Nil, t1, t2).isEmpty ) // XmlComparison type class\n</code></pre> <p>Wherever an XmlComparison exists an Equal instance can be created.  The results of a compare include both a path to the difference and a fully pattern matchable XML difference ADT.</p>"},{"location":"Advanced/XML_Equality/EqualityBasics/#types-covered","title":"Types Covered","text":"<p>The full set of the Scales Xml Model is covered by the equality framework:</p> <ul> <li>QName</li> <li>Attribute</li> <li>Attributes</li> <li> <p>XmlItem</p> </li> <li> <p>Elem</p> </li> <li>XmlTree</li> <li>XmlPath</li> <li> <p>Anything that can be seen as Iterator[PullType]</p> </li> <li> <p>Doc and various DocLike implementations</p> </li> </ul> <p>QNames by default do not compare with the prefix(unlike Canonical Xml, where string comparisons including prefixes are expected), only the namespace (as per =:=).  This implies that documents created by different systems using different prefixes are still comparable, a different implicit default Equal[QName] instance can change that behaviour.</p> <p>XmlTrees/XmlPath's etc are converted to Iterator[PullType] in order to compare.  No attempt to match DTDs or encoding are made, but the rest of a given document (Doc and DocLike implementations) will be.</p> <p>Within the comparison framework the comparison for all the types are combined, the QName Equal typeclass is used throughout, including for the Attribute comparison, which is used in turn by the Elem - which is finally used by Stream comparisons.  </p> <p>This lookup is performed implicitly, allowing for individual parts to be swapped out, if the developer wants prefixes to be tested.  Either use name based overriding in the relevant scope or mix the traits differently to provide custom behaviour (and not import ScalesXml._)</p> <p>Note The three different kinds of QNames each have a different type and, as such, using === to compare different types will not work.  Using compare, however, will:</p> <pre><code>  val ns = Namespace(\"uri:prefixed\")\n\nval p = ns.prefixed(\"p\")\n\nval nonPrefixedQName = ns(\"a1\") // prefixed\nval prefixedQName = p(\"a1\")\n\n// both of the above are semantically the same\nassertTrue(\"compare(nonPrefixedQName, prefixedQName).isEmpty\", compare(nonPrefixedQName, prefixedQName).isEmpty)\n</code></pre>"},{"location":"Advanced/XML_Equality/EqualityBasics/#why-join-adjacent-text-and-cdata","title":"Why Join Adjacent Text and CData?","text":"<p>Scales Xml equality makes three default design decisions, prefixes aren't generally relevant only the namespace is (unless you tell it to use QName Token comparison) and to join adjacent CData and Text.</p> <p>The reason for joining adjacent CData and Text nodes is to simplify the comparison of text.  CData can always be written as Text nodes, and a parser is free to \"split\" a single logical Text node into multiple smaller text nodes.  Scales neither forces joining of the text nodes at parse time nor when adding child nodes, as such to usefully compare they must be joined.</p> <p>This also allows testing content from different sources without issue.</p>"},{"location":"Advanced/XML_Equality/EqualityBasics/#removing-comments-and-pis","title":"Removing Comments And PIs","text":"<p>The default comparison logic treats both Comments and PIs as relevant for comparison.  This design choice meets expectations for the majority of XML documents.</p> <p>In the event that Comments and PIs should not be compared the implicits can be overridden in scope with:</p> <pre><code>  val root = po(\"root\")\nval child = po(\"child\")\n\nimport LogicalFilters._\n\nimplicit def toDefaultStreamComparison[T](\nimplicit tv : T =&gt; StreamComparable[T], ic : XmlComparison[XmlItem],\nec : XmlComparison[Elem], qe : Equal[QName], , qe : Equal[QName], qnameTokenComparison : Option[(ComparisonContext, String, String) =&gt; Boolean]) : XmlComparison[T] = new StreamComparisonWrapper( new StreamComparison( x =&gt; removePIAndComments(joinText(x))\n)( ic, ec, qe, qnameTokenComparison) )\n\nval x1 = &lt;(root) /( \"0\", \"1\", CData(\"2\"), Comment(\"c2\"), \"3\", \"4\", PI(\"i\",\"s\"),\nchild /( \"s1\", CData(\"s2\"), Comment(\"cs2\"), \"s3\"\n),\nchild /( CData(\"s22\"), Comment(\"cs22\"), PI(\"i\",\"s\"), \"s23\" ),\nPI(\"i\",\"s\"), \"5\", CData(\"6\"), Comment(\"c6\") )\n\n\nval x2 = &lt;(root) /( \"0\",\"1\",CData(\"2\"), \"3\",\"4\", child /( \"s1\", CData(\"s2\"), \"s3\" ),\nchild /( CData(\"s22\"), \"s23\" ),\n\"5\", CData(\"6\") )\nassertTrue( \" x1 === x2 \", x1 === x2)\n</code></pre>"},{"location":"Advanced/XML_Equality/EqualityBasics/#why-not-use-canonical-xml","title":"Why Not Use Canonical XML?","text":"<p>Testing Xml Equality is not always straightforward, a standard approach however exists : Canonical Xml - a defined w3c standard approach to serialization.  Canonical Xml treats QName prefixes themselves as relevant, if an XML processor changes a prefix, that document is no longer comparable under Canonical Xml (No Namespace Prefix Rewriting).</p> <p>Whilst the justifications for the prefix rewriting rule in Canonical Xml is, within the context of embedded XPaths or XML QNames (their prefixes only make sense within that document), understandable Scales takes the position that this is far rarer an occasion than simple Xml as a data transport usage.  However, as with the rest of Scales, this default too is customisable.</p> <p>The problem, and it stops the Canonical Xml reasoning as well, is that a producing application can re-write the prefixes for embedded QNames or XPaths before sending.  WSDM applications often meet this (see Apache Muse for examples of this).  Scales is of course, by default, not aware of such usage - see here for details on how to configure Scales to be QName token aware.  In short, it can be as simple as declaring this in the correct scope:</p> <pre><code>  implicit val defaultQNameTokenComparison = Option(qnamesEqual _)\n</code></pre> <p>Canonical Xml also forces redundant namespace declarations to be removed (Superfluous Namespace Declarations).  Scales typically only uses namespace declarations for predictable document processing - i.e. loading and saving should be 1:1 in usage - however it also can if necessary leverage declarations for QName Token handling in both Attribute values and Text/CData nodes.</p> <p>Similarly the following approaches to Canonical Xml actually may break data assumptions of equality:</p> <ul> <li>normalize line feeds</li> <li>normalize attribute values</li> <li>Default attributes are added to each element</li> </ul> <p>The latter may cause issues with certain receiving processors and depends on a validation / schema enrichment working.  Scales concerns itself with the documents actually being compared.</p> <p>In short - Scales offers a typed and more flexible approach to equality than Canonical Xml handling.</p>"},{"location":"Advanced/XML_Equality/XmlComparison/","title":"XmlComparison - What, Where &amp; How Was It Different","text":"<p>The XmlComparison typeclass is fairly simple with one function:</p> <pre><code>  def compare( calculate : Boolean , context : ComparisonContext, left : T, right : T) : Option[(XmlDifference[_], ComparisonContext)]\n</code></pre> <p>All instances are created via defs and implicit lookup.  As such, where runtime performance of comparison is a concern you should cache an appropriately scoped instance via <code>implicitly</code>.</p> <p>The reason for using defs is that the behaviour of any one XmlComparison instance is configurable.  Substituting the <code>defaultQNameTokenComparison</code> in a given scope will affect both XmlItem and Attribute value comparison.</p> <p>To retrieve the full information about what changed use the compare function (mixed into the scales.xml package):</p> <pre><code>  def compare[T : XmlComparison]( left : T, right : T) : Option[(XmlDifference[_], ComparisonContext)] =\nimplicitly[XmlComparison[T]].compare(true, ComparisonContext(), left, right)\n</code></pre> <p>As can be seen, this simply provides a starting context and informs the framework to calculate both the path to a difference and a detailed ADT for what was different (XmlDifference).</p>"},{"location":"Advanced/XML_Equality/XmlComparison/#the-compare-function","title":"The compare Function","text":"<p>Any implementing instance of XmlComparison must provide a compare implementation, for example a user provided XmlItem comparison, it is recommended to respect the following conventions:</p> <ol> <li>When calculate is false, its a signal that no detailed result is expected and is likely called from ===</li> <li>Use the comparison context to handle namespace lookups</li> <li>Respect defaultQNameTokenComparison, if code has defined it in scope you must assume the developer wants at least the context to be generated (irrespective of calculate being false or not).</li> </ol>"},{"location":"Advanced/XML_Equality/XmlComparison/#the-calculate-parameter","title":"The calculate Parameter","text":"<p>The calculate parameter when false indicates that any difference returned as scales.xml.equals.SomeDifference.noCalculation, i.e. a dummy Some value.  The purpose of the false parameter is for a simple comparison via === and the derived Equal type class.</p> <p>A value of false will also disable, unless a defaultQNameTokenComparison is defined in scope, the generation of relevant ComparisonContexts, further reducing allocation for simple equality checks.</p> <p>However when set true it instructs both the use of ComparisonContexts and that the return value is as detailed as possible.</p>"},{"location":"Advanced/XML_Equality/XmlComparison/#comparisoncontext","title":"ComparisonContext","text":"<p>ComparisonContext is a stack of potential namespace contexts (for both the left and right side), the parent context and the BasicPath from the start of the compare.  BasicPath is defined as:</p> <pre><code>  // {ns}Local -&gt; count\ntype BasicPathA = (QName, Map[String, Int])\ntype BasicPath = List[BasicPathA] </code></pre> <p>and maintains a count against each QName as it navigates down a given tree.  ComparisonContext provides a simplified string path via the pathString function, for example the following output:</p> <pre><code>/{}root[1]/{uri:prefixed}elem[2]/{uri:prefixed}elem[1]\n</code></pre> <p>In addition to identifying where something is different it could be used to decide if the difference is relevant within a custom XmlComparison instance.</p> <p>NamespaceContext is used by both XmlComparison and by the serialisation mechanisms and acts a stack of prefix -&gt; namespace mappings that have been defined in the given trees.  The namespace prefixes used by PrefixedQName attributes and element are combined with any defined prefixes from the elements namespace map.</p> <p>When comparing a stream the position within that iterator is also set upon returning from comparison - streamPosition.  Calling a ComparisonContexts toDifferenceAsStream with one of the compared xml objects will provide a Stream[PullType] with the xml from the start of the document to the diffence.  Callers are responsible for ensuring the input is restartable (i.e. if it was over an http stream that a bufferred stream was used) and that the conversion function matches (by default it follows the same convention of joinTextAndCData that the stream comparison uses).  For example:</p> <pre><code>val x = loadXml(scales.utils.resource(this, \"/data/Nested.xml\")).rootElem\n\n// create a difference\nval y = x.fold_!( _.\\*.\\*(\"urn:default\"::\"ShouldRedeclare\") )(_ =&gt; Remove())\n\nval Some((diff, context)) = compare[XmlTree](x, y)\n\n// the stream from the start of the document to the difference\nval upTo = context.toDifferenceAsStream(x)\n\n// as a string\nval upToStr = asString(upTo.iterator)\n\nassertEquals(232, upToStr.size)\n</code></pre>"},{"location":"Advanced/XML_Equality/XmlComparison/#return-value","title":"Return Value","text":"<p>The return value indicates:</p> <ol> <li>The presence of a difference (Some vs None)</li> <li>The difference itself (XmlDifference), and</li> <li>The relevant context for this difference (allowing access to namespaces and path)</li> </ol> <p>If the calculate parameter is false the default implementations return scales.xml.equals.SomeDifference.noCalculation.  Custom XmlComparison instances my choose to return other values but it is not recommended.</p>"},{"location":"Advanced/XML_Equality/XmlComparison/#xmldifference","title":"XmlDifference","text":"<p>The XmlDifference ADT provides information about the type of difference and provides the objects themselves that contained the difference.  The XmlComparison framework attempts to provide, when using calculate true, finely detailed information about what was different via case classes, allowing simplified pattern matching to analyse differences.</p> <p>The full ADT is present via the [./doc/scales/xml/equals/XmlDifference.html scala docs, Known Subclasses] or directly via [./api.sxr/scales/xml/equals/XmlDifference.scala.html the source]. To aid explanation the following are presented:</p> <ul> <li>DifferentTypes( left : PullType, right : PullType)</li> <li>AttributeValueDifference( left : Attribute, right : Attribute )</li> <li>DifferentNumberOfMiscs( left : Miscs, right : Miscs, isProlog : Boolean )</li> <li>ElemAttributeDifference( left : Elem, right : Elem, attributesDifference : AttributesDifference )</li> </ul> <p>DifferentTypes is returned when a given left PullType is of different type to the right PullType.  AttributeValueDifference indicates the names are the same but the values differ between the two attributes.</p> <p>DifferentNumberOfMiscs indicates that the prolog (isProlog == true) or end miscallaeneous (isProlog == false) have a different count and provides the Miscs themselves for further investigation.  ElemAttributeDifference contains the elements that contained an AttributesDifference, which in turn has a number of possible matching types (DifferentNumberOfAttributes, DifferentValueAttributes and MissingAttributes).</p>"},{"location":"Advanced/XML_Equality/XmlComparison/#qname-token-handling","title":"QName Token Handling","text":"<p>QName Tokens are attributes or Text nodes that contain a prefixed qname such as:</p> <pre><code>  &lt;elem xmlns:pre=\"uri:test\" value=\"pre:alocal\"&gt;pre:local&lt;/elem&gt;\n</code></pre> <p>Applications are free to redefine the prefix used between runs, making things difficult for comparison.  Scales provides two simple mechanism to help solve this problem:</p> <ol> <li>ComparisonContext</li> <li>defaultQNameTokenComparison</li> </ol> <p>The former is covered above and provides the NamespaceContext's for the left and right side objects under comparison.  This information is calculated either when the  defaultQNameTokenComparison is defined or calculate is true.</p> <p>The defaultQNameTokenComparison is defined as:</p> <pre><code>  implicit val defaultQNameTokenComparison : Option[(ComparisonContext, String, String) =&gt; Boolean] = None\n</code></pre> <p>Simply defining this function will also enable the creation of the contexts (irrespective of the value of calculate).  The parameters are simply the ComparisonContext together with the left and right object's string values.</p> <p>As such a simple way to enable qname comparisons is to define and override, within an appropriate scope:</p> <pre><code>  implicit val defaultQNameTokenComparison = Option(qnamesEqual _)\n</code></pre> <p>qnamesEqual is defined as:</p> <pre><code>  def qnamesEqual(context : ComparisonContext, str : String, str2 : String) = {\n// split both, if one has and the other not, then its false anyway\nval sp1 = str.split(\":\")\nval sp2 = str2.split(\":\")\nif (sp1.size == 2 &amp;&amp; sp2.size == 2) {\nsp1(1) == sp2(1) &amp;&amp; { // values match\n// look up prefixes\n(for{ lnc &lt;- context.leftNamespaceContext\nrnc &lt;- context.rightNamespaceContext\nlns &lt;- lnc.mappings.get(sp1(0))\nrns &lt;- rnc.mappings.get(sp2(0))\n} yield lns == rns\n).\ngetOrElse(false)\n}\n} else str == str2\n}\n</code></pre> <p>Which should show an obvious limitation, it can only work when there is a single qname in the text.  This would stop it being able to handle embedded XPaths for example.</p> <p>As such the functionality is exposed to the library users to customise.  Any useful other implementations are more than welcome as contributions :-)</p>"},{"location":"Getting_Started/HowToUse/","title":"How To Use","text":"<p>To use ScalesXml you must use the following imports (where the objects ScalesUtils and ScalesXml import implicits).</p> <pre><code>  import scales.utils._\nimport ScalesUtils._\nimport scales.xml._\nimport ScalesXml._\n\nval prefixedNamespace = Namespace(\"uri:test\").prefixed(\"pre\")\nval prefixedQName = prefixedNamespace(\"prefixed\")\n\nval elem = Elem(prefixedQName)\n\nprintln(\"local name is \"+localName(elem))\n</code></pre>"},{"location":"Getting_Started/HowToUse/#parsing-and-xpaths","title":"Parsing and XPaths","text":"<pre><code>  // Contains the document\nval doc = loadXml(new FileReader(\"document.xml\"))\n\n// gets Path from the documents root \nval path = top(doc)\n\n// query for all nodes that match the XPath\npath.\\*(\"NoNamespace\").\\*(prefixedQName)\n</code></pre>"},{"location":"Getting_Started/MemoryOptimisation/","title":"Scales Xml Optimisation","text":""},{"location":"Getting_Started/MemoryOptimisation/#disclaimer","title":"Disclaimer","text":"<p>Measuring and comparing XML models is fraught with difficulty and will often vary based on individual XML documents and application behaviour. </p>"},{"location":"Getting_Started/MemoryOptimisation/#introduction","title":"Introduction","text":"<p>A basic premise of Scales Xml is to separate the structure of XML from its contents, allowing optimisation on both axes.  Due to the Elem also being the child node container scala.xml can only leverage identical subtrees, not individual elements.</p> <p>The speed of parsing is also directly related to how much garbage is produced during the parse.  For example pre 0.1 versions of Scales used Path directly to build the resulting tree, creating many intermediate Path objects - 99.9% of which were immediately ready for garbage collection.  Swapping this into a mutable stack of mutable trees improved parsing performance 20-30%.</p> <p>Scales takes a flexible approach to memory management allowing the user to tune how much work is performed to reduce allocations during the parse and total resulting memory usage.</p>"},{"location":"Getting_Started/MemoryOptimisation/#options-for-memory-optimisation","title":"Options for memory optimisation","text":"<p>Scales Xml's separation of structure and content in particular allows the following areas of memory optimisation:</p> <ul> <li>QNames</li> <li>Attributes</li> <li>Elems</li> <li>Subtrees</li> <li>Structure</li> </ul> <p>During several optimisation rounds it was clear that the largest wins were due to QName and simple Elem (no attributes or namespaces) usage, and as such forms basis for the default parsing behaviour. </p> <p>QNames often repeat during individual XML documents and, of course, across them in a given domain.  QNames can also be shared between Attributes and Elems.  There are two direct benefits of optimising at the QName/ level:</p> <ol> <li>Reduced memory consumption</li> <li>Reduced garbage during parsing</li> </ol> <p>However, the time taken to cache QNames is significant for smaller documents (e.g. 150-200 elements) where typically any garbage effects are less likely to impact performance.</p> <p>The below diagrams illustrate the relative parsing performance of Scales Xml against Scala XML (2.9.1) and the two common Xerces implementations.  For all sizes of documents Scales is notably faster than Scala XML, and for larger documents it is considerable faster.</p> <p></p> <p></p> <p>The most important point is that the developer has a choice, when needed, in how to optimise and that Scales allows the developer to easily enhance the default optimisations.  The defaults use a thread safe singleton to cache, but developers can also choose to implement a ThreadLocal or a per parse strategy if it better fits.  If in doubt profile.</p>"},{"location":"Getting_Started/MemoryOptimisation/#resulting-sizes","title":"Resulting Sizes","text":"<p>The Recon test (See ParsingPerformance - PerfData.reconDoc) approximates a few real world problems tackled by Scales has very few attributes and a flat structure.  The 40,000 Recon size is chosen to demonstrate the resulting memory sizes (obtained by the excellent Yourkit profiler):</p> <p></p> <p>The default optimisation (which is also 10-20% faster on larger documents than Scala) strikes a very good balance between speed and memory usage.  The Scales parsing optimisations also result in QName and Elem cache sizes of 2.24KB and 2.18KB respectively (the Elem caches are used by HighMemory and QNameElemTree Optimisations), showing more than a clear space saving.</p> <p>The slightly slower to parse (but still faster than Scala XML) Tree based optimisations reduce immediate memory usage by over 15Mb less than Scala XML for the same document, in fact the two Tree optimisations also consume 5Mb less than the Xerces deferred DOM impl.</p> <p>Full Elem caching alone (not including Elem + Tree) reduces the overall performance by up to 15%, putting it around (and sometimes below) the parsing performance of Scala XML.  The potential memory savings are also limited by how often the attribute or namespace values are identical, and it is often better to simply cache attribute values if there is a restricted range available.</p> <p>See QName and Elem Memory Usage for more details on default memory saving.</p>"},{"location":"Getting_Started/MemoryOptimisation/#memory-consumption-during-parsing","title":"Memory Consumption During Parsing","text":"<p>The memory consumed by Scales in its default configuration is close to or better than Xerces / JAXP default without the nasty expansion upon using it.</p> <p></p> <p>However as can be seen above the memory usage can be substantially reduced, in a similar fashion to Xerces Deferred processing (albeit immutably so).</p>"},{"location":"Getting_Started/MemoryOptimisation/#overall-parsing-performance","title":"Overall Parsing Performance","text":"<p>The overall parsing performance of Scales Xml, with default Optimisation, is around 20-25% faster than Scala XML for small to mid size documents to 40-45% faster for larger documents.</p> <p>The larger the amount of data and the level of repeated structure the greater the difference in Scales Xml parsing performance.</p> <p>Scales is less than 10% slower than JAXP Deferred for smaller documents and for larger documents up to 30% slower.  For fully parsed documents however its less than 5% slower for smaller documents and up to 30% faster for larger docs.</p>"},{"location":"Getting_Started/MemoryOptimisation/#special-case-pull-parsing-via-onqnames","title":"Special Case - Pull Parsing via onQNames","text":"<p>A key feature of Scales is the XML Pull (via StAX) based parsing that leverages Scalaz Iteratees.  A shining example of this being onQNames, the recon file being a driving force behind its design.</p> <p>In the recon example what is actually interesting is three simple hash maps (Int -&gt; Int), as such the memory usage of a onQNames -&gt; map was examined.  Both the overall resulting savings (over a full tree) and the runtime memory requirements to parse are examined using the following code:</p> <pre><code>    object Recon {\nimport PerfData.ns\n\nval Part = List(ns(\"Recon\"), ns(\"Parts\"), ns(\"Part\"))\nval Bom = List(ns(\"Recon\"), ns(\"BOMs\"), ns(\"BOM\"))\nval Rec = List(ns(\"Recon\"), ns(\"Records\"), ns(\"Record\"))\n\nval id = ns(\"id\")\nval version = ns(\"version\")\n\n}\n\ncase class Recon(val parts : Map[Int, Int], val boms : Map[Int, Int],\nval recs : Map[Int, Int])\n\n\nimport Recon._\nimport Functions._\n\nval xml = pullXml(new java.io.StringReader(s)).it\nfoldOnDone( xml )( Recon(), onDone( List(onQNames(Part), onQNames(Bom), onQNames(Rec)) )) {\n(recon, qNamesMatch) =&gt; if (qNamesMatch.size == 0)\nrecon\nelse {\n// we expect only one to match in this pattern\t  \nval matched = qNamesMatch.head\nval qnames = matched._1  // to get an onDone it must be defined\nval x = matched._2.get\n// only one child\nval pair = (text(x.\\*(id)).toInt, text(x.\\*(version)).toInt)\n\nqnames match {\ncase Part =&gt; recon.copy( parts = recon.parts + pair )\ncase Bom =&gt; recon.copy( boms = recon.boms + pair )\ncase Rec =&gt; recon.copy( recs = recon.recs + pair )\n}\n}\t\t\t   }\n</code></pre> <p>In short the memory requirements for the maps are 13.7MB, whereas the test itself can run in under 45MB, albeit with a high GC overhead. As such thats roughly 25MB required to actually parse the entire document in such a high level api.</p> <p>Also worth noting is that it takes 42MB to generate the document</p> <p>See the [PullParsing.html Pull Parsing], [RepeatedSections.html Pulling Repeated Sections] and the PullTests themselves for examples on how this approach can be best leveraged in your code.</p>"},{"location":"Getting_Started/ScalesXmlIntro/","title":"Scales Xml Overview","text":"<p>Scales Xml, in addition to immutability, aims to focus on these separate concerns:</p> <p>Correctness</p> <ul> <li>XmlItems such as Text, Comments, PIs and CData are not containing nodes, they cannot have children and they cannot contain invalid characters </li> <li>QNames are a fundamental piece of XML and are treated as first class citizens</li> <li>Elements are a QName, the attributes they contain, the namespaces they declare and also do not directly have children</li> <li>Attributes are combinations of either a PrefixedQName or NoNamespaceQName and a value</li> </ul> <p>Structure and manipulation</p> <ul> <li>Structure of XML (Tree) is separated from the contents of the Xml, allowing maximal re-use</li> <li>Operations on XML (Path - a Zipper over Tree) is separated from both the contents and the structure</li> <li>Changing any update to individual XML Element or Items will not cause cascading changes in the rest of the structure (function of Path)</li> <li>Transformations on XML Trees (via Path) should be composable and simple to follow.</li> <li>The data model is the same for both Push and Pull parsing (with the addition of EndElem for XmlPull)</li> </ul> <p>XML Comprehensions - XPath</p> <ul> <li>Navigation through XML is either through Path directly or the inbuilt XPath syntax</li> <li>Syntax closely resembles normal XPath leveraging, for example, Paths ability to navigate parents</li> <li>Syntax should separate the navigation of elements from available predicates as far as possible (niceties such as *QName remain) </li> <li>Syntax should not rely on string interpretation but on types (QName objects used directly)</li> <li>String based XPath 1.0 querying based on Jaxen is however available</li> <li>XPaths are used as a basis for Tree transformation</li> <li>The full XPath axe are available (with the exception of the namespace axis)</li> </ul> <p>Pull API</p> <ul> <li>Based on javax.xml.stream, allowing optimisations from jaxp/stax upgrades</li> <li>Uses the same types as the SAX based parser</li> <li>Leverages Scalaz Iteratees to provide processing of the event stream</li> <li>You can choose how to process an xml stream, should your code control the flow, the enumerator or a mixture?</li> <li>Immutable transformations on streams</li> <li>Provides an Iteratee to process XPath like locations via a ${cscala}List[QName]${cend}</li> <li>Provides a combinator (onDone) to iterate over ResumableIters allowing simplified XML parsing</li> <li>Non blocking IO based parsing via Aalto</li> <li>Scales adds the concept of resumable iteration:</li> </ul> <pre><code>  // think resumable folds without cps plugin\ntype ResumableIter[E,A] = IterV[E, (A, IterV[E,_])]\n</code></pre> <p>Comprehensive Serialisation Support</p> <ul> <li>SerializerFactory / Serializer Typeclasses allow plugable serialisation schemes</li> <li>SerializeableXml Typeclass allows serializing of all XML through a single consistent interface</li> <li>Lazily create XML using EphemeralStreams and Iterator[PullType]</li> <li>Developers can customise the serialisation process while maintaining correctness</li> <li>Use XHTML style tag ends  for empty elements</li> <li>Serialise your attributes in an order of your choosing</li> <li>Or choose to abandon certain correctness checks in favour of speed when you know that your XML inputs and outputs are always correct</li> </ul> <p>JAXP Support</p> <ul> <li>XSLT transformation support</li> <li>Conversion to other XML DOMs</li> <li>Use of JAXP serialisation - e.g. pretty printing</li> <li>javax.xml.validation support</li> <li>Aims to hide all JAXP implementation inconsistencies</li> </ul> <p>Xml Equality</p> <ul> <li>Compare xml items against each other</li> <li>Full control over QName handling</li> <li>Full control over QName values (attributes or text)</li> <li>Provides information about what is different and where</li> <li>Provides a simple conversion to scalaz.Equal</li> </ul> <p>Performance</p> <ul> <li>Up to 20% faster than scala.xml</li> <li>Lower memory usage than both scala.xml and JAXP/DOM</li> <li>Parsing memory usage can be optimised for given usage</li> </ul>"},{"location":"Getting_Started/Setup/","title":"Setup","text":"<p>Maven users should use scales-xml_2.12 as the dependency (org.scalesxml as the group).</p> <p>Scales is cross compiled for 2.11 and 2.12.</p>"},{"location":"Getting_Started/Setup/#sbt-011x","title":"Sbt 0.11.x +","text":"<pre><code>libraryDependencies ++= Seq(\n// just for the core library\n\"org.scalesxml\" %% \"scales-xml\" % \"0.5.0-M1\" // and additionally use these for String based XPaths\n\"org.scalesxml\" %% \"scales-jaxen\" % \"0.5.0-M1\" intransitive(),\n\"jaxen\" % \"jaxen\" % \"1.1.3\" intransitive()\n// to use Aalto based parsing\n\"org.scalesxml\" %% \"scales-aalto\" % \"0.5.0-M1\"\n)\n</code></pre>"},{"location":"Getting_Started/release_notes/0.1.0/","title":"0.1.0","text":""},{"location":"Getting_Started/release_notes/0.1.0/#initial-release","title":"Initial Release","text":"<p>Scales Xml is an alternative XML library, providing correctness first, a unified model for push and pull, Scalaz Iteratee based pulls, performance gains and possible customisations for parsing, serializing and transformations. </p> <p>The content of the DOM is separated from the structure itself.  This lends itself to space savings in both parsing and the resulting DOM, but doesn't sacrifice performance in doing so. </p> <p>Manipulation and querying is based on tree Zippers (Path), with the XPath like querying system based directly upon them.  A DSL provides simple construction and aids in transformations, which can be performed via paths across the tree. </p> <p>See the release site for the docs including performance information and many examples.</p>"},{"location":"Getting_Started/release_notes/0.2.1/","title":"0.2.1","text":""},{"location":"Getting_Started/release_notes/0.2.1/#matching-and-jaxp-compatibility-fixes","title":"Matching and JAXP compatibility fixes","text":"<p>Scales 0.2.1 is bug fix release.  Source compatibility is maintained but a recompile is likely necessary.</p> <p>Barring further bug fixes this is probably the last release before migrating to the new xsbt (which also includes migrating all of the plugins) and introduction of various subprojects.</p> <p>Fixes include:</p> <ul> <li>JAXP TrAX compatible with both the Saxon and Sun JDK approach to StAX reading (see issue 1)</li> <li>Matching on QName alone (Attribute or Elem) requires calling the .m or .matcher function.</li> </ul> <p>Known issues:</p> <ol> <li>Using TrAX for serializing or transforming will not, in the JDK - due to the JDK ignoring them, process PROLOG and end misc items.  Saxon does process this correctly.  Use the scales.traxSourceShouldSerialize system property (set to true) if these events are important to you, its simply much faster.  When left as its non Xalan defaul - false - no extra serialization is required and transformations will be faster (but loose wrapping misc items).</li> <li>Xalan users don't really have choice here as it doesn't support StAX readers for transformations (no StAXStream2SAX)</li> </ol>"},{"location":"Getting_Started/release_notes/0.2/","title":"0.2","text":""},{"location":"Getting_Started/release_notes/0.2/#performance-flexibility-and-correctness-improvements","title":"Performance, Flexibility and Correctness Improvements","text":"<p>Scales 0.2 is an incremental release aimed at improved overall performance for the Xml Pull api and correctness.  </p> <p>It now reaches my correctness, usability and performance aims from almost 2 years ago when I started the project.</p> <p>Additional functionality includes:</p> <ul> <li>XPath union</li> <li>Path sorting now allows sorting tuples of (T, Path)</li> </ul>"},{"location":"Getting_Started/release_notes/0.2/#performance-improvements","title":"Performance Improvements","text":"<ul> <li>Iteratee based parsing with onDone (onQNames) is now 40-50% faster and allocates even less memory</li> <li>Deep XPath searches (\\\\\\) are 20-25% faster</li> <li> <p>XPath non-sorted / duplicate filtered results can be &gt;30% faster (due to evaluation choice)</p> </li> <li> <p>Document order sorting and filtering only when required (15-20% faster for exact or non matching XPaths)</p> </li> <li>XPath general performance gains of 5-10% and lower memory allocations</li> </ul>"},{"location":"Getting_Started/release_notes/0.2/#additional-flexibility-for-xpath-evaluation-choices","title":"Additional Flexibility For XPath Evaluation Choices","text":"<ul> <li>The developer can now choose to lazily evaluate XPaths</li> <li>The resulting Iterable[XPath] can be lazily traversed</li> <li>The raw unfiltered and unsorted paths can be traversed</li> </ul>"},{"location":"Getting_Started/release_notes/0.2/#correctness-improvements","title":"Correctness Improvements","text":"<ul> <li>Attribute axis results are now typed</li> <li>Document order results from Attribute Axis</li> <li>XPath union (|) maintains ordering</li> </ul>"},{"location":"Getting_Started/release_notes/0.2/#release-improvements","title":"Release Improvements","text":"<ul> <li>Reduced dependencies (now only Scalaz, slf4j and commons-codec)</li> <li>Removed JUnit test helpers</li> <li>Scalaz version upped to 6.0.3</li> </ul> <p>See the release site for the docs including performance information and many examples.</p>"},{"location":"Getting_Started/release_notes/0.3-RC6/","title":"0.3 RC6","text":"<p>This is a feature release, adding a the full set of useful XPath Axe, string based XPath evaluation - via a popular open source XPath library, useful equality testing, a lot of new documentation and many smaller improvements in syntax and usability.</p> <p>This version has been built with xsbt 0.11.x and migrated to github.  This releases documentation can be found here and provides many examples on how to use Scales Xml.</p>"},{"location":"Getting_Started/release_notes/0.3-RC6/#all-the-axe-youll-ever-need","title":"All the Axe you'll ever need","text":"<p>Scales 0.3 adds the following axe:</p> <ul> <li>preceding-sibling (preceding_sibling_::)</li> <li>following-sibling (following_sibling_::)</li> <li>descendant (descendant_::)</li> <li>following (following_::)</li> <li>preceding (preceding_::)</li> <li>ancestor (ancestor_::)</li> <li>ancestor-or-self (ancestor_or_self_::)</li> <li>descendant-or-self (descendant_or_self_::)</li> </ul> <p>This provides all of the XPath 1 and 2 axe (namespace axis excluded).</p>"},{"location":"Getting_Started/release_notes/0.3-RC6/#enhanced-internal-xpath-queries","title":"Enhanced internal XPath queries","text":"<ul> <li>position() (pos)         pos_&lt;, pos_==, pos_&gt;</li> <li>last() (last)         last_&lt;, last_==, last_&gt;</li> <li>position() == last() (pos_eq_last)</li> <li>Easier to extend and re-use queries and axe         xfilter, xmap, xflatMap</li> </ul>"},{"location":"Getting_Started/release_notes/0.3-RC6/#string-base-xpath-evaluation","title":"String base XPath evaluation","text":"<ul> <li>Evaluate normal XPath 1.0 strings to XmlPaths</li> <li>Evaluates to an Iterable[Either[AttributePath, XmlPath]] or,</li> <li>get[T] a value directly from XPath 1.0 (e.g. get[String](\"normalize(//*)\")) </li> <li>Allows querying for the few predicates and XPaths that Scales cannot process (and dynamic queries of course)</li> <li>Optional dependency</li> </ul>"},{"location":"Getting_Started/release_notes/0.3-RC6/#new-xpathfunctions","title":"New xpath.Functions","text":"<ul> <li>Unified interface for XPath function handling</li> <li>text, QName and Boolean typeclasses</li> <li>Implementations for all relevant Scales Xml types<ul> <li>string( attribute ) makes sense whilst string( QName ) does not</li> </ul> </li> </ul>"},{"location":"Getting_Started/release_notes/0.3-RC6/#new-xmlcomparison-framework-29x-only","title":"New XmlComparison framework (2.9.x only)","text":"<ul> <li>Compare Xml structures and types</li> <li>Customisable comparison rules</li> <li>Default Scalaz === Equal type classes</li> <li>XmlComparison type classes provide full details of differences:<ul> <li>A QName based path to the difference</li> <li>The objects which are different</li> </ul> </li> </ul>"},{"location":"Getting_Started/release_notes/0.3-RC6/#extra-fun","title":"Extra Fun","text":"<ul> <li>Forwards and Backwards Path Iterators (used by following and preceding)</li> <li>DuplicateFilter now works with the Scalaz Equal typeclass</li> <li>Using AttributeQNames with the tuple arrow now creates QNames as you'd expect </li> <li>DslBuilder allows direct manipulation of trees via folding</li> <li>Simplify the Builder usage why /(&lt;(Elem(\u2026 ) when you can just /(Elem)?</li> <li>Java 1.7 JAXP implementation checks - Schema validation is optimised (no serialization)</li> </ul>"},{"location":"Getting_Started/release_notes/0.3-RC6/#how-to-use","title":"How To Use","text":"<p>Scales 0.3 moves to Sonatype under the organisation org.scalesxml, with support for 2.8.1, 2.8.2, 2.9.1 and 2.9.2.  As such add:</p> <pre><code>libraryDependencies ++= Seq(\n  // just for the core library\n  \"org.scalesxml\" %% \"scales-xml\" % \"0.3-RC6\"\n  // or, use this instead for String based XPaths (Jaxen, also includes the core)\n  \"org.scalesxml\" %% \"scales-jaxen\" % \"0.3-RC6\"\n)\n</code></pre> <p>to your xsbt builds or use scales-xml_2.9.2 as the id when using Maven.</p>"},{"location":"Getting_Started/release_notes/0.3-RC7/","title":"0.3 RC7","text":"<p>This is a feature release, adding a the full set of useful XPath Axe, string based XPath evaluation - via a popular open source XPath library, useful equality testing, a lot of new documentation and many smaller improvements in syntax and usability.</p> <p>This version has been built with xsbt 0.11.x and migrated to github.  This releases documentation can be found here and provides many examples on how to use Scales Xml.</p>"},{"location":"Getting_Started/release_notes/0.3-RC7/#new-in-rc7","title":"New in RC7","text":"<p>Significant performance and memory improvements, for small to medium size documents up to 30% faster than Scala XML and within 10% of Xerces/JAXP.</p> <p>Memory usage can be significantly reduced (10% reduction over previous Scales releases) and through TreeOptimisations with only a 5% performance hit but a further 30% reduction in memory usage - suitable for high volume servers.</p>"},{"location":"Getting_Started/release_notes/0.3-RC7/#all-the-axe-youll-ever-need","title":"All the Axe you'll ever need","text":"<p>Scales 0.3 adds the following axe:</p> <ul> <li>preceding-sibling (preceding_sibling_::)</li> <li>following-sibling (following_sibling_::)</li> <li>descendant (descendant_::)</li> <li>following (following_::)</li> <li>preceding (preceding_::)</li> <li>ancestor (ancestor_::)</li> <li>ancestor-or-self (ancestor_or_self_::)</li> <li>descendant-or-self (descendant_or_self_::)</li> </ul> <p>This provides all of the XPath 1 and 2 axe (namespace axis excluded).</p>"},{"location":"Getting_Started/release_notes/0.3-RC7/#enhanced-internal-xpath-queries","title":"Enhanced internal XPath queries","text":"<ul> <li>position() (pos)         pos_&lt;, pos_==, pos_&gt;</li> <li>last() (last)         last_&lt;, last_==, last_&gt;</li> <li>position() == last() (pos_eq_last)</li> <li>Easier to extend and re-use queries and axe         xfilter, xmap, xflatMap</li> </ul>"},{"location":"Getting_Started/release_notes/0.3-RC7/#string-base-xpath-evaluation","title":"String base XPath evaluation","text":"<ul> <li>Evaluate normal XPath 1.0 strings to XmlPaths</li> <li>Evaluates to an Iterable[Either[AttributePath, XmlPath]] or,</li> <li>get[T] a value directly from XPath 1.0 (e.g. get[String](\"normalize(//*)\")) </li> <li>Allows querying for the few predicates and XPaths that Scales cannot process (and dynamic queries of course)</li> <li>Optional dependency</li> </ul>"},{"location":"Getting_Started/release_notes/0.3-RC7/#new-xpathfunctions","title":"New xpath.Functions","text":"<ul> <li>Unified interface for XPath function handling</li> <li>text, QName and Boolean typeclasses</li> <li>Implementations for all relevant Scales Xml types<ul> <li>string( attribute ) makes sense whilst string( QName ) does not</li> </ul> </li> </ul>"},{"location":"Getting_Started/release_notes/0.3-RC7/#new-xmlcomparison-framework-29x-only","title":"New XmlComparison framework (2.9.x only)","text":"<ul> <li>Compare Xml structures and types</li> <li>Customisable comparison rules</li> <li>Default Scalaz === Equal type classes</li> <li>XmlComparison type classes provide full details of differences:<ul> <li>A QName based path to the difference</li> <li>The objects which are different</li> </ul> </li> </ul>"},{"location":"Getting_Started/release_notes/0.3-RC7/#extra-fun","title":"Extra Fun","text":"<ul> <li>Forwards and Backwards Path Iterators (used by following and preceding)</li> <li>DuplicateFilter now works with the Scalaz Equal typeclass</li> <li>Using AttributeQNames with the tuple arrow now creates QNames as you'd expect </li> <li>DslBuilder allows direct manipulation of trees via folding</li> <li>Simplify the Builder usage why /(&lt;(Elem(\u2026 ) when you can just /(Elem)?</li> <li>Java 1.7 JAXP implementation checks - Schema validation is optimised (no serialization)</li> <li>Direct SAX XMLReader support</li> </ul>"},{"location":"Getting_Started/release_notes/0.3-RC7/#how-to-use","title":"How To Use","text":"<p>Scales 0.3 moves to Sonatype under the organisation org.scalesxml, with support for 2.8.1, 2.8.2, 2.9.1 and 2.9.2.  As such add:</p> <pre><code>libraryDependencies ++= Seq(\n  // just for the core library\n  \"org.scalesxml\" %% \"scales-xml\" % \"0.3-RC7\"\n  // or, use this instead for String based XPaths (Jaxen, also includes the core)\n  \"org.scalesxml\" %% \"scales-jaxen\" % \"0.3-RC7\"\n)\n</code></pre> <p>to your xsbt builds or use scales-xml_2.9.2 as the id when using Maven.</p>"},{"location":"Getting_Started/release_notes/0.3.1/","title":"0.3.1","text":"<p>This is a feature release, adding a the full set of useful XPath Axe, string based XPath evaluation - via a popular open source XPath library, useful equality testing, even more performance gains, a lot of new documentation and many smaller improvements in syntax and usability.</p> <p>This version has been built with xsbt 0.11.x and migrated to github.  This releases documentation can be found here and provides many examples on how to use Scales Xml.</p>"},{"location":"Getting_Started/release_notes/0.3.1/#all-the-axe-youll-ever-need","title":"All the Axe you'll ever need","text":"<p>Scales 0.3.1 adds the following axe:</p> <ul> <li>preceding-sibling (preceding_sibling_::)</li> <li>following-sibling (following_sibling_::)</li> <li>descendant (descendant_::)</li> <li>following (following_::)</li> <li>preceding (preceding_::)</li> <li>ancestor (ancestor_::)</li> <li>ancestor-or-self (ancestor_or_self_::)</li> <li>descendant-or-self (descendant_or_self_::)</li> </ul> <p>This provides all of the XPath 1 and 2 axe (namespace axis excluded).</p>"},{"location":"Getting_Started/release_notes/0.3.1/#enhanced-internal-xpath-queries","title":"Enhanced internal XPath queries","text":"<ul> <li>position() (pos)         pos_&lt;, pos_==, pos_&gt;</li> <li>last() (last)         last_&lt;, last_==, last_&gt;</li> <li>position() == last() (pos_eq_last)</li> <li>Easier to extend and re-use queries and axe         xfilter, xmap, xflatMap</li> </ul>"},{"location":"Getting_Started/release_notes/0.3.1/#string-base-xpath-evaluation","title":"String base XPath evaluation","text":"<ul> <li>Evaluate normal XPath 1.0 strings to XmlPaths</li> <li>Evaluates to an Iterable[Either[AttributePath, XmlPath]] or,</li> <li>get[T] a value directly from XPath 1.0 (e.g. get[String](\"normalize(//*)\")) </li> <li>Allows querying for the few predicates and XPaths that Scales cannot process (and dynamic queries of course)</li> <li>Optional dependency</li> </ul>"},{"location":"Getting_Started/release_notes/0.3.1/#new-xpathfunctions","title":"New xpath.Functions","text":"<ul> <li>Unified interface for XPath function handling</li> <li>text, QName and Boolean typeclasses</li> <li>Implementations for all relevant Scales Xml types<ul> <li>string( attribute ) makes sense whilst string( QName ) does not</li> </ul> </li> </ul>"},{"location":"Getting_Started/release_notes/0.3.1/#new-xmlcomparison-framework-29x-only","title":"New XmlComparison framework (2.9.x only)","text":"<ul> <li>Compare Xml structures and types</li> <li>Customisable comparison rules</li> <li>Default Scalaz === Equal type classes</li> <li>XmlComparison type classes provide full details of differences:<ul> <li>A QName based path to the difference</li> <li>The objects which are different</li> </ul> </li> </ul>"},{"location":"Getting_Started/release_notes/0.3.1/#performance-improvements","title":"Performance Improvements","text":"<p>Significant performance and memory improvements, for small to medium size documents up to 30% faster than Scala XML and within 10% of Xerces/JAXP.</p> <p>Memory usage can be significantly reduced (10% reduction over previous Scales releases) and through TreeOptimisations with only a 5% performance hit but a further 30% reduction in memory usage - suitable for high volume servers.</p>"},{"location":"Getting_Started/release_notes/0.3.1/#extra-fun","title":"Extra Fun","text":"<ul> <li>Forwards and Backwards Path Iterators (used by following and preceding)</li> <li>DuplicateFilter now works with the Scalaz Equal typeclass</li> <li>Using AttributeQNames with the tuple arrow now creates QNames as you'd expect </li> <li>DslBuilder allows direct manipulation of trees via folding</li> <li>Simplify the Builder usage why /(&lt;(Elem(\u2026 ) when you can just /(Elem)?</li> <li>Java 1.7 JAXP implementation checks - Schema validation is optimised (no serialization)</li> <li>Direct SAX XMLReader support</li> </ul>"},{"location":"Getting_Started/release_notes/0.3.1/#how-to-use","title":"How To Use","text":"<p>Scales 0.3.1 moves to Sonatype under the organisation org.scalesxml, with support for 2.8.1, 2.8.2, 2.9.1, 2.9.2 and 2.10.0-M6.  As such add:</p> <pre><code>libraryDependencies ++= Seq(\n  // just for the core library\n  \"org.scalesxml\" %% \"scales-xml\" % \"0.3.1\"\n  // or, use this instead for String based XPaths (Jaxen, also includes the core)\n  \"org.scalesxml\" %% \"scales-jaxen\" % \"0.3.1\"\n)\n</code></pre> <p>to your xsbt builds or use scales-xml_2.9.2 as the id when using Maven.</p>"},{"location":"Getting_Started/release_notes/0.3/","title":"0.3","text":"<p>This is a feature release, adding a the full set of useful XPath Axe, string based XPath evaluation - via a popular open source XPath library, useful equality testing, even more performance gains, a lot of new documentation and many smaller improvements in syntax and usability.</p> <p>This version has been built with xsbt 0.11.x and migrated to github.  This releases documentation can be found here and provides many examples on how to use Scales Xml.</p>"},{"location":"Getting_Started/release_notes/0.3/#all-the-axe-youll-ever-need","title":"All the Axe you'll ever need","text":"<p>Scales 0.3 adds the following axe:</p> <ul> <li>preceding-sibling (preceding_sibling_::)</li> <li>following-sibling (following_sibling_::)</li> <li>descendant (descendant_::)</li> <li>following (following_::)</li> <li>preceding (preceding_::)</li> <li>ancestor (ancestor_::)</li> <li>ancestor-or-self (ancestor_or_self_::)</li> <li>descendant-or-self (descendant_or_self_::)</li> </ul> <p>This provides all of the XPath 1 and 2 axe (namespace axis excluded).</p>"},{"location":"Getting_Started/release_notes/0.3/#enhanced-internal-xpath-queries","title":"Enhanced internal XPath queries","text":"<ul> <li>position() (pos)         pos_&lt;, pos_==, pos_&gt;</li> <li>last() (last)         last_&lt;, last_==, last_&gt;</li> <li>position() == last() (pos_eq_last)</li> <li>Easier to extend and re-use queries and axe         xfilter, xmap, xflatMap</li> </ul>"},{"location":"Getting_Started/release_notes/0.3/#string-base-xpath-evaluation","title":"String base XPath evaluation","text":"<ul> <li>Evaluate normal XPath 1.0 strings to XmlPaths</li> <li>Evaluates to an Iterable[Either[AttributePath, XmlPath]] or,</li> <li>get[T] a value directly from XPath 1.0 (e.g. get[String](\"normalize(//*)\")) </li> <li>Allows querying for the few predicates and XPaths that Scales cannot process (and dynamic queries of course)</li> <li>Optional dependency</li> </ul>"},{"location":"Getting_Started/release_notes/0.3/#new-xpathfunctions","title":"New xpath.Functions","text":"<ul> <li>Unified interface for XPath function handling</li> <li>text, QName and Boolean typeclasses</li> <li>Implementations for all relevant Scales Xml types<ul> <li>string( attribute ) makes sense whilst string( QName ) does not</li> </ul> </li> </ul>"},{"location":"Getting_Started/release_notes/0.3/#new-xmlcomparison-framework-29x-only","title":"New XmlComparison framework (2.9.x only)","text":"<ul> <li>Compare Xml structures and types</li> <li>Customisable comparison rules</li> <li>Default Scalaz === Equal type classes</li> <li>XmlComparison type classes provide full details of differences:<ul> <li>A QName based path to the difference</li> <li>The objects which are different</li> </ul> </li> </ul>"},{"location":"Getting_Started/release_notes/0.3/#performance-improvements","title":"Performance Improvements","text":"<p>Significant performance and memory improvements, for small to medium size documents up to 30% faster than Scala XML and within 10% of Xerces/JAXP.</p> <p>Memory usage can be significantly reduced (10% reduction over previous Scales releases) and through TreeOptimisations with only a 5% performance hit but a further 30% reduction in memory usage - suitable for high volume servers.</p>"},{"location":"Getting_Started/release_notes/0.3/#extra-fun","title":"Extra Fun","text":"<ul> <li>Forwards and Backwards Path Iterators (used by following and preceding)</li> <li>DuplicateFilter now works with the Scalaz Equal typeclass</li> <li>Using AttributeQNames with the tuple arrow now creates QNames as you'd expect </li> <li>DslBuilder allows direct manipulation of trees via folding</li> <li>Simplify the Builder usage why /(&lt;(Elem(\u2026 ) when you can just /(Elem)?</li> <li>Java 1.7 JAXP implementation checks - Schema validation is optimised (no serialization)</li> <li>Direct SAX XMLReader support</li> </ul>"},{"location":"Getting_Started/release_notes/0.3/#how-to-use","title":"How To Use","text":"<p>Scales 0.3 moves to Sonatype under the organisation org.scalesxml, with support for 2.8.1, 2.8.2, 2.9.1 and 2.9.2.  As such add:</p> <pre><code>libraryDependencies ++= Seq(\n  // just for the core library\n  \"org.scalesxml\" %% \"scales-xml\" % \"0.3\"\n  // or, use this instead for String based XPaths (Jaxen, also includes the core)\n  \"org.scalesxml\" %% \"scales-jaxen\" % \"0.3\"\n)\n</code></pre> <p>to your xsbt builds or use scales-xml_2.9.2 as the id when using Maven.</p>"},{"location":"Getting_Started/release_notes/0.4.1/","title":"0.4.1","text":"<p>This release represents a move to Scalaz 6.0.4, which is binary incompatible with 6.0.3.  As such to ease adoption of 6.0.4 Scales Xml 0.4.1 has the same goodness found in 0.3.1 (see here for the 0.3.1 release notes).</p>"},{"location":"Getting_Started/release_notes/0.4.1/#how-to-use","title":"How To Use","text":"<p>Scales 0.4.1 supports for 2.8.1, 2.8.2, 2.9.1, 2.9.2 and 2.10.0-M6.  As such add:</p> <pre><code>libraryDependencies ++= Seq(\n  // just for the core library\n  \"org.scalesxml\" %% \"scales-xml\" % \"0.4.1\"\n  // or, use this instead for String based XPaths (Jaxen, also includes the core)\n  \"org.scalesxml\" %% \"scales-jaxen\" % \"0.4.1\"\n)\n</code></pre> <p>to your xsbt builds or use scales-xml_2.9.2 as the id when using Maven.</p>"},{"location":"Getting_Started/release_notes/0.4.2/","title":"0.4.2","text":"<p>This release is a performance update/fix for pull parsing using onQNames / iterate which adds a healthy boost to most usage scenarios (issue #3).</p> <p>Please note that due to (issue #4) intransitive() must be added to the libraryDependencies for scales-jaxen and a direct entry for jaxen itself (also intransitive()) should be used - see below.</p> <p>The 0.4.x releases represent a move to Scalaz 6.0.4, which is binary incompatible with 6.0.3.  See here for the 0.3.1 release notes.</p>"},{"location":"Getting_Started/release_notes/0.4.2/#how-to-use","title":"How To Use","text":"<p>Scales 0.4.2 supports for 2.8.1, 2.8.2, 2.9.1, 2.9.2 and 2.10.0-M6.  As such add:</p> <pre><code>libraryDependencies ++= Seq(\n  // just for the core library\n  \"org.scalesxml\" %% \"scales-xml\" % \"0.4.2\"\n  // and additionally use these for String based XPaths\n  \"org.scalesxml\" %% \"scales-jaxen\" % \"0.4.2\" intransitive(),\n  \"jaxen\" % \"jaxen\" % \"1.1.3\" intransitive()\n)\n</code></pre> <p>to your xsbt builds or use scales-xml_2.9.2 as the id when using Maven.</p>"},{"location":"Getting_Started/release_notes/0.4.3/","title":"0.4.3","text":"<p>This release is a minor feature release adding only (issue #5) - support of direct optionality for Text, Attributes and ItemOrElem in the XML builder DSL.</p> <p>Please note that due to SI-6271 the 2.10.0-M7 build should not be used with lazyRaw/viewed, the default usage is unaffected.</p> <p>The new site can be found here and uses the new 2.10 scaladoc.  Users of Scalaz 6.0.3 can use 0.3.3 instead.</p>"},{"location":"Getting_Started/release_notes/0.4.3/#how-to-use","title":"How To Use","text":"<p>Scales 0.4.3 supports for 2.8.1, 2.8.2, 2.9.1, 2.9.2, 2.10.0-M6 and 2.10.0-M7.  As such add:</p> <pre><code>libraryDependencies ++= Seq(\n  // just for the core library\n  \"org.scalesxml\" %% \"scales-xml\" % \"0.4.3\"\n  // and additionally use these for String based XPaths\n  \"org.scalesxml\" %% \"scales-jaxen\" % \"0.4.3\" intransitive(),\n  \"jaxen\" % \"jaxen\" % \"1.1.3\" intransitive()\n)\n</code></pre> <p>to your xsbt builds or use scales-xml_2.9.2 as the id when using Maven.</p>"},{"location":"Getting_Started/release_notes/0.4.4/","title":"0.4.4","text":"<p>This is a minor feature release with one performance enhancement to the pull parsing iterate function (issue #9) increasing its performance by up to 40%.  It also adds some documentation (issue #13) and fixes up two bugs:</p> <ol> <li>TreeOptimisation (issue #7)</li> <li>XHTML Serialization only allows 10 empty tags (issue #6)</li> </ol> <p>The new site can be found here and uses the new 2.10 scaladoc.</p>"},{"location":"Getting_Started/release_notes/0.4.4/#how-to-use","title":"How To Use","text":"<p>Scales 0.4.4 supports for 2.8.1, 2.8.2, 2.9.1, 2.9.2, 2.10.0-RC2.  As such add:</p> <pre><code>libraryDependencies ++= Seq(\n  // just for the core library\n  \"org.scalesxml\" %% \"scales-xml\" % \"0.4.4\"\n  // and additionally use these for String based XPaths\n  \"org.scalesxml\" %% \"scales-jaxen\" % \"0.4.4\" intransitive(),\n  \"jaxen\" % \"jaxen\" % \"1.1.3\" intransitive()\n)\n</code></pre> <p>to your xsbt builds or use scales-xml_2.9.2 as the id when using Maven.</p> <p>If using the 2.10.0 RC candidates and sbt 0.12.1 please also use:</p> <pre><code> cross CrossVersion.full\n</code></pre> <p>against the dependencies (as the RCs are not guaranteed to be binary compatible).</p>"},{"location":"Getting_Started/release_notes/0.5.0-M1/","title":"0.5.0 M1","text":"<p>This milestone provides the basis for the 0.5.0 release.</p> <p>Although a milestone, this release is intended as the RC starting point, as such a kind request goes out to all users to give the milestone a spin.  The earlier feedback is given the earlier we have a chance to refine the design before going RC.  Many thanks in advance.</p> <p>Scales Xml 0.5.0 fixes two bugs:</p> <ol> <li>issue #23 - Replace should be allowed for root Elems in foldPositions</li> <li>issue #24 - string() does not include CDATA</li> </ol> <p>and brings the following new features and improvements:</p> <ol> <li>issue #19 - Add empty and isNi functions</li> <li>issue #18 - Optional trees in DSL</li> <li>issue #16 - Smaller packages</li> <li>issue #15 - Async Xml Pull</li> </ol> <p>A large thank you for contributions goes to a number of the Scales community, for build, Travis-CI integration and documentation help.</p>"},{"location":"Getting_Started/release_notes/0.5.0-M1/#optional-dsl","title":"Optional DSL","text":"<p>The Optional DSL documentation can be found here.  The DSL provides the ability to collapse trees in the builder where no actual child text or attribute exists.</p> <p>It works both for simple examples:</p> <pre><code>val ns = Namespace(\"uri:test\")\n\nval root = ns(\"root\")\nval optional = ns(\"optional\")\n\ndef someOptionalText: Option[String] = ???\n\n// optional is converted into an instance of OptionalDslBuilder allowing ?~&gt; to be called\nval optionalxml = root /( optional ?~&gt; someOptionalText )\n</code></pre> <p>and for more complex optional trees, combining fully with the existing DSL.  In the above example the root node will either be empty or contain an optional element with text.</p>"},{"location":"Getting_Started/release_notes/0.5.0-M1/#smaller-packages","title":"Smaller Packages","text":"<p>Based on both feedback from the Scala community at large and user experience Scales Xml has reached the size where its no longer useful to maintain the previous code layout.</p> <p>Scales has been broken up into smaller functional units both within the utils and xml packages.  Deprecated functionality has, in addition, been moved to the Scales Extras repo.  While the key imports are still found in the main package and implicit objects optional functionality has been moved out into appropriate sub-packages, as have implementation details.</p>"},{"location":"Getting_Started/release_notes/0.5.0-M1/#async-xml-parsing","title":"Async Xml Parsing","text":"<p>Scales 0.5 adds support for Async parsing via the Aalto-xml pull parser.  Aalto adds the notion of an incomplete event, returning control to the calling code when more data is needed instead of blocking like traditional pull parsing.</p> <p>Scales leverages this and enumeratees to provide yet more flexible pull parsing options.</p> <p>The new site can be found here.</p>"},{"location":"Getting_Started/release_notes/0.5.0-M1/#how-to-use","title":"How To Use","text":"<p>Scales 0.5.0-M1 is built against 2.8.1, 2.8.2, 2.9.1, 2.9.2 and 2.10 (2.10.1 is therefore also supported).  As such add:</p> <pre><code>libraryDependencies ++= Seq(\n  // just for the core library\n  \"org.scalesxml\" %% \"scales-xml\" % \"0.5.0-M1\"\n  // and additionally use these for String based XPaths\n  \"org.scalesxml\" %% \"scales-jaxen\" % \"0.5.0-M1\" intransitive(),\n  \"jaxen\" % \"jaxen\" % \"1.1.3\" intransitive()\n  // to use Aalto based parsing\n  \"org.scalesxml\" %% \"scales-aalto\" % \"0.5.0-M1\"\n)\n</code></pre> <p>to your xsbt builds or use scales-xml_2.10.0 as the id when using Maven.</p>"},{"location":"Getting_Started/release_notes/0.6.0/","title":"0.6.0","text":"<p>The 0.6.0 release removes support for scala versions below 2.11, migrates to scalaz-iteratees and adds support for 2.13's new collection approach.</p> <p>Build wise it's moved to maven and github actions to simplify rolling out any future fixes, similarly the docs have migrated from the home-brew site builder to mkdocs.  The feature scope is: </p> <ol> <li>#51 - Migration from the old IterV to the newer Scalaz iteratee library</li> <li>#52 - Scala 2.13 support</li> </ol>"},{"location":"Getting_Started/release_notes/0.6.0/#scalaz-iteratee","title":"Scalaz Iteratee","text":"<p>The pull api (and async pull api) remains the same, however user iteratee usage will have to change.  Largely this involves swapping Cont and Done for cont and done and migrating enumeratee / run usage to:</p> <pre><code>(iteratee &amp;= iteratorEnumerator(pull.it)) run\n</code></pre> <p>instead of</p> <pre><code>iteratee(pull.it) run\n</code></pre> <p>this is because enumerators are no longer implicitly bound, things are notably more verbose.  Scalaz provides a good selection of useful starting enumerators.</p> <p>Also note that Iteratee[E,A] is a type alias for Iteratee[E,Id,A] so everything is \"wrapped\" in an Id container (Id[X]=X), as such you may need to specify types to get a proper compilation.</p>"},{"location":"Getting_Started/release_notes/0.6.0/#scala-213-support","title":"Scala 2.13 support","text":"<p>2.13 re-worked much of the internal collection logic, including CanBuildFrom.  Scales required the ability to swap out the actual container used for Tree's in order to reduce allocation cost (yielding better performance).</p> <p>As such there is a compatibility layer working around most of this unpleasantness, however for compatibility CanBuildfrom is still implicitly required in the apis.</p> <p>None of this should affect 2.13 usage but please raise an issue should you find one.</p>"},{"location":"Getting_Started/release_notes/about/","title":"About","text":"<p>Scales Xml is an alternate xml library for Scala providing a coherent model, querying and manipulation via an XPath like syntax, flexible DSLs, better performance, highly customisable equality framework and both a blocking and non-blocking Iteratee based pull api.</p>"},{"location":"Parsing_XML/AsyncPull/","title":"Async Pull","text":"<p>Traditional push models (DOM/SAX parsing) and the StAX pull standard both block on streams when they need more data.  The [FasterXML/aato-xml Aalto XML] project aims to change that.</p> <p>Instead of blocking Aalto XML enhances the StAX parser adding an event type EVENT_INCOMPLETE to signal that no more data could be read.  Scales Xml adds the AsyncParser to wrap this behaviour (and a number of supporting io classes) providing a single function to capture the interaction:</p> <pre><code>  def nextInput(d: DataChunk): Input[EphemeralStream[PullType]]\n</code></pre> <p>where the [./doc/scales/utils/io/DataChunk.html DataChunk] ADT is either EOFData, EmptyData or an array of Byte.  The resulting Scalaz IterV.Input provides the mirror of either EOF, Empty or El for a given stream of PullType.</p> <p>This allows a chunked parsing approach, the developer can fully control the use of the resulting xml.  Calling nextInput with a filled DataChunk won't necessarily return an El if not enough bytes were \"pushed\" into nextInput.  The resulting EphemeraStream can only be reliably traversed once - and is used as a safer memory usage stream only.</p> <p>An example direct usage of this api:</p> <pre><code>  import scales.utils.io._\nvar channel: java.nio.channels.ReadableByteChannel = ??? // a channel \nvar wrappedChannel: DataChunker[DataChunk] = channel.wrapped\nvar b: DataChunk = EmptyData\n\nwhile(b != EOFData) { // real code could return thread to a pool with another thread selecting on multiple channels\nb = wrappedChannel.nextChunk\nval s = parser.nextInput(b)\ns(\nel = e =&gt; { // use stream of PullTypes\nvar st = e\nwhile(!st.isEmpty) {\nval pullType = st.head()\n// use pullType\nst = st.tail()\n}\n},\nempty = ,// needs more data\neof = // xml message is now finished - no more events possible\n)\n}\n</code></pre> <p>The '''wrapped''' method is an implicit converter that lifts a java.nio channel.ReadableByteChannel into a DataChunker[DataChunk].  This interface provides nextChunk and a CloseOnNeed with the redundant type parameter allowing an Enumerator to be created over DataChunker (Enumerators can only enumerate over a shape F[_]).</p>"},{"location":"Parsing_XML/AsyncPull/#integrating-with-enumeratees-enumtomany","title":"Integrating With Enumeratees - enumToMany","text":"<p>ResumableIter'atees within Scales allow calculations to be suspended and resumed with intermediate results which is very useful for streamed XML processing.  When a new value is available a Done((value, cont)) is returned and when more data is required a Cont.  The same standard Iteratee semantics (Done or Cont) can be used to \"map\" over an Iteratee to convert one sequence of typed events into sequences of other types.  This mapping process is modelled by Enumeratees.</p> <p>The key Enumeratee provided by Scales is enumToMany, a mapping Enumeratee:</p> <pre><code>  def enumToMany[E, A, R]( dest: ResumableIter[A,R])( toMany: ResumableIter[E, EphemeralStream[A]]): ResumableIter[E, R]\n</code></pre> <p>The interesting part is the EphemeralStream of type A returned by the mapping Iteratee 'toMany', this allows any number of results for a single input of type E.  If toMany or indeed dest returns EOF, so must the resulting Iteratee.</p> <p>The following simple example shows how enumToMany can work:</p> <pre><code>  def iTo(lower: Int, upper: Int): EphemeralStream[Int] =\nif (lower &gt; upper) EphemeralStream.empty else EphemeralStream.cons(lower, iTo(lower + 1, upper))\n\nval i = List(1,2,3,4).iterator\n\nval (res, cont) = enumToMany(sum[Int])( mapTo( (i: Int) =&gt; El(iTo(1, i)) ) )(i).run\nassertEquals(20, res)\nassertTrue(\"should have been done\", isDone(cont))\n</code></pre> <p>The toMany Iteratee here is mapTo called over the iTo function, for each input i it returns 1 -&gt; i.  The destination Iteratee sums the resulting stream, so the list 1 -&gt; 4 then provides a sequence of 1, 1, 2, 1, 2 3, 1, 2, 3, 4 totalling 20.</p> <p>In the above example sum and mapTo are simple IterV's that are, in the mapTo case ''restarted'' for each input of \"i\", and in sum's case is run until EOF is sent.  This restarting with ResumableIter's allows the computation to be continued after intermediate results are returned, making them ideal for XML processing.</p>"},{"location":"Parsing_XML/AsyncPull/#async-pull-with-enumtomany","title":"Async Pull with enumToMany","text":"<p>A simple streaming example can be seen below:</p> <pre><code>    val url = scales.utils.resource(this, \"/data/BaseXmlTest.xml\")\n\nval channel : DataChunker[DataChunk] = Channels.newChannel(url.openStream()).wrapped\n\nval parser = AsyncParser()\n\nval strout = new java.io.StringWriter()\nval (closer, iter) = pushXmlIter( strout )\n\nval enumeratee = enumToMany(iter)(parser.iteratee)\nval ((out, thrown), cont) = enumeratee(channel).run\n\nassertFalse( \"shouldn't have thrown\", thrown.isDefined)\nassertTrue(\"should have been auto closed\", closer.isClosed)\nassertTrue(\"Channel itself should have been auto closed\", channel.isClosed)\n</code></pre> <p>The .iteratee method calls (by default) the AsyncParser.parse function which wraps the AsyncParser into a ResumableIter[DataChunk, EphemeralStream[PullType]], where the stream itself is the result of calling AsyncParser.nextInput.  It will return Done with a stream of events when enough data is processed.  As can be seen from the type it fits perfectly with toMany parameter of enumToMany, for a given chunk it may return many PullTypes.</p> <p>The pushXmlIter is a serializing IterV that pushes PullType into an outputstream.  enumToMany then joins these two Iteratees to provide streaming.</p> <p>The example also shows that the resources are all automatically closed upon completion.  The parser and DataChunker resources themselves are CloseOnNeed instances and therefore also early closing (for example when there has been enough data processed).</p>"},{"location":"Parsing_XML/FullParsing/","title":"Full XML Doc Parsing","text":"<p>Parsing a full XML document in Scales can be very straightforward:</p> <pre><code>  val doc = loadXml(new FileReader(\"document.xml\"))\n</code></pre> <p>The input to loadXml is an InputSource, a PathOptimisationStrategy and a Loaner[SAXParser].  Defaults are provided for the strategy and Loaner, but can be overridden.</p> <p>Conversions exist (pulled in via ScalesXml._) from InputStream, Readers and URL to ease the use of the api.</p> <p>PathOptimisationStrategys allow the developer to tweak both the memory consumption and generation (and therefore the performance).  The default optimisation caches QNames across an application but does not attempt to cache elements or attributes.  Caching elements and attributes can lead to significant memory savings at the cost of parsing performance.  </p> <p>As the names suggests PathOptimisationStrategies could also choose to optimise whole sub-trees, tests have not shown a general case where this is beneficial however (the cost of matching the tree typically outweighing potential memory savings).</p> <p>Loaner is a simple interface to obtain SAXParser instances, other non default instances can be provided, such as JTagSoup or simply to allow customisations of SAX properties.  The default SAX parser pool also takes care of common threading issues.</p>"},{"location":"Parsing_XML/FullParsing/#direct-sax-xmlreader-usage","title":"Direct SAX XMLReader Usage","text":"<p>As of Scales 0.3 there is direct support for SAX parsers via the loadXmlReader function.  This follows the same Loaner approach as the normal JAXP factories, for example:</p> <pre><code>  import org.xml.sax.XMLReader\n\nobject NuValidatorFactoryPool extends scales.utils.SimpleUnboundedPool[XMLReader] with DefaultSaxSupport {\ndef create = {\nimport nu.validator.htmlparser.{sax,common}\nimport sax.HtmlParser\nimport common.XmlViolationPolicy\n\nval reader = new HtmlParser\nreader.setXmlPolicy(XmlViolationPolicy.ALLOW)\nreader.setXmlnsPolicy(XmlViolationPolicy.ALLOW)\nreader\n}      }    val xmlFile = resource(this, \"/data/html.xml\")\nval nuxml = loadXmlReader(xmlFile, parsers = NuValidatorFactoryPool)\n</code></pre> <p>Developers can also call readXml directly with a given XMLReader instance instead of using the pooled version.</p> <p>If a given XMLReader cannot work with the DefaultSaxSupport it can override the appropriate functions.  For example TagSoup doesn't support XmlVersion information, as such a TagSoupFactoryPool would look like:</p> <pre><code>object TagSoupFactoryPool extends scales.utils.SimpleUnboundedPool[XMLReader] with DefaultSaxSupport {\n// doesn't support xml version retrieval\noverride def getXmlVersion( reader : XMLReader ) : AnyRef =\nnull\n\ndef create = {\nimport org.ccil.cowan.tagsoup.Parser\nval reader = new Parser\n// disable namespaces\nreader.setFeature(Parser.namespacesFeature, false)\nreader\n}      }\n</code></pre>"},{"location":"Parsing_XML/PullParsing/","title":"Pull Parsing","text":"<p>Scales Pull Parsing leverages StAX, the JAXP streaming api, and Scalaz Iteratees, to allow flexible parsing of large documents or many documents in memory constrained environment (e.g. a high performance server).</p> <p>Scales, as with full tree parsing, allows configurable optimisation strategies and the pull parser used.  The optimisation strategy type, unlike full tree parsing is a MemoryOptimisationStrategy and does not allow for tree path optimisations.</p> <p>The input to all pull xml functions is a sax.InputSource, which allows the same conversions as for a full tree parse.</p> <p>A curio exists with pullXmlCompletely, which uses the pull parser to load xml Docs.  This may be of use in an environment where the StAX parser performs better than SAX, but tests have shown lower memory consumption and higher performance when using SAX to parse full trees.</p> <p>Some of the advanced features of Pull Parsing may require importing Scalaz as well:</p> <pre><code>  import scalaz._\nimport Scalaz._\nimport IterV._ // may not always be required\n</code></pre>"},{"location":"Parsing_XML/PullParsing/#pull-model","title":"Pull Model","text":"<p>The Scales Pull Model adds only EndElem to create PullType:</p> <pre><code>  type PullType = Either[XmlEvent, EndElem]\n</code></pre> <p>Where XmlEvent is exactly the same Elem, XmlItem model as with full Trees.  This is possible because Scales separates the structure of data and the data itself.</p> <p>The developer only has to learn one single difference to be able to use pull parsing.  For example the code to process a stream is simply:</p> <pre><code>  val pull = pullXml(source)\n\nwhile( pull.hasNext ){\npull.next match {\ncase Left( i : XmlItem ) =&gt; // do something with an XmlItem\ncase Left( e : Elem ) =&gt; // do something with start of a new element\ncase Right(endElem) =&gt; // do something with the end of an element\n}\n}\n</code></pre>"},{"location":"Parsing_XML/PullParsing/#resource-management","title":"Resource Management","text":"<p>The above example has a serious potential flaw, if anything in the while loop throws the resource cannot be closed.  To allow greater control of the resource Scales provides the following interface (full api details present [./doc/scales/utils/resources/CloseOnNeed.html here]):</p> <pre><code>  trait CloseOnNeed {\ndef ++ (close2: CloseOnNeed): CloseOnNeed\ndef closeResource : Unit\n}\n</code></pre> <p>Importantly closeResource only closes a resource once.  This resource is directly available when calling pullXmlResource.</p> <p>pullXml itself is also a Closable and provides the same guarantee, close only attempts to close the resource once.</p> <p>Both results provide the isClosed function (via the IsClosed interface) allowing code to trust that it has been closed. (NB - a future version may choose to expose this in the type system, but integrating with the ARM library makes more sense).</p> <p>What CloseOnNeed also adds is the ++ function, which combines one CloseOnNeed with another to create a new CloseOnNeed that closes the other two resources.  This allows chaining of xml files (via pull iterators).</p>"},{"location":"Parsing_XML/PullParsing/#simple-reading-of-repeated-sections","title":"Simple Reading Of Repeated Sections","text":"<p>Given an xml document with the following format:</p> <pre><code>  &lt;root&gt;\n&lt;nested&gt;\n&lt;ofInterest&gt; &lt;!-- Collect all of these --&gt;\n&lt;lotsOfInterestingSubTree&gt;\n&lt;/lotsOfInterestingSubTree&gt;\n&lt;/ofInterest&gt;\n..\n    &lt;/nested&gt;\n....\n  &lt;/root&gt;\n</code></pre> <p>where the interesting parts are always repeating in the same location, we can model the interesting parts a simple List of QNames (very simplified XPath):</p> <pre><code>  val pull = pullXml(new java.io.InputStream(\"\"))\n\nval qnames = List(\"root\"l, \"nested\"l, \"ofInterest\"l)\n\n// only returns /root/nested/ofInterest paths\nval itr : Iterator[XmlPath] = iterate(qnames, pull)\n</code></pre> <p>The resulting Iterator contains paths with single child parents up to the root and all of the subtree of interest.</p> <p>For more complex repeated sections see here for examples.</p>"},{"location":"Parsing_XML/PullParsing/#buffering-and-identifying-xml-messages","title":"Buffering And Identifying Xml Messages","text":"<p>When parsing xml messages it is often necessary to identify the type of the message before further processing, for example what kind of soap request is being sent, or what is the root element?</p> <p>To help with this issue Scales pull parsing offers the ability to \"peek\" into an event stream and replay the events again to fully process them.</p> <p>A simple example is processing soap messages based on the first body element, you may want to choose different code paths based on this, but require elements in the header to do so.  The usage is simple via the  capture function and the skip/skipv functions:</p> <pre><code>  val xmlpull = // stream capture\n\nval captured = capture(xmlpull)\n// either the path or None if its EOF or no longer possible\nval identified = skip(List(2, 1))(captured) run\n\nval processor = identified.map(........\n\n// restart the stream from scratch\nprocessor.process(captured.restart)\n</code></pre> <p>The result from skip is simply Option[XmlPath], if the stream runs out or its no longer possible to get that position it is None. Only as much of the stream is read as needed, it will stop on the Left(Elem) event.</p> <p>NB to only identify the first element, simply use skip(Nil) instead (or skipv()).</p>"},{"location":"Parsing_XML/RepeatedSections/","title":"Pulling Repeated Sections","text":"<p>Scales leverages and extends Scalaz Iteratees to allow resuming an Iteratee.  This resuming action is simply returning the current value and the next continuation when done (ResumableIter).  The iterate function, as shown here, uses this approach to provide a single path repeating section.</p> <p>Many documents however have a more complex structure, of many repeated or alternating structures, the following shows the various structures supported by the combination of onDone and onQNames:</p>"},{"location":"Parsing_XML/RepeatedSections/#supported-repeating-section-examples","title":"Supported Repeating Section Examples","text":"<p>Its far easier to discuss the solution with a few examples of the problem: </p>"},{"location":"Parsing_XML/RepeatedSections/#alternating-and-repeating-elements","title":"Alternating and Repeating Elements","text":"<pre><code>  &lt;root&gt;\n&lt;nested&gt;\n&lt;ofInterest&gt; &lt;!-- Collect all of these --&gt;\n&lt;lotsOfInterestingSubTree&gt;\n&lt;/lotsOfInterestingSubTree&gt;\n&lt;/ofInterest&gt;\n&lt;alsoOfInterest&gt; &lt;!-- Collect all of these --&gt;\njust some text\n      &lt;/alsoOfInterest&gt;\n&lt;/nested&gt;\n...\n    &lt;nested&gt;\n....\n  &lt;/root&gt;\n</code></pre> <p>It should be noted that monadic serial composition of onQNames would also work here, onDone is not absolutely necessary, although as we will see it is more general..</p>"},{"location":"Parsing_XML/RepeatedSections/#grouped-repeating","title":"Grouped Repeating","text":"<pre><code>  &lt;root&gt;\n&lt;nested&gt;\n&lt;ofInterest&gt; &lt;!-- Collect all of these --&gt;\n&lt;lotsOfInterestingSubTree&gt;\n&lt;/lotsOfInterestingSubTree&gt;\n&lt;/ofInterest&gt;      &lt;/nested&gt;\n...\n    &lt;nested&gt;\n&lt;alsoOfInterest&gt; &lt;!-- Collect all of these --&gt;\njust some text\n      &lt;/alsoOfInterest&gt;\t&lt;/nested&gt;\n....\n  &lt;/root&gt;\n</code></pre>"},{"location":"Parsing_XML/RepeatedSections/#repeating-nested","title":"Repeating Nested","text":"<pre><code>  &lt;root&gt;\n&lt;nested&gt;\n&lt;ofInterest&gt; &lt;!-- Collect all of these --&gt;\n&lt;lotsOfInterestingSubTree&gt;\n&lt;smallKeyValues&gt; &lt;!-- Collect all of these --&gt;\n&lt;key&gt;toLock&lt;/key&gt;\n&lt;value&gt;fred&lt;/value&gt;\n&lt;/smallKeyValues&gt;\n&lt;/lotsOfInterestingSubTree&gt;\n&lt;/ofInterest&gt;\n&lt;/nested&gt;\n...\n    &lt;nested&gt;\n....\n  &lt;/root&gt;\n</code></pre>"},{"location":"Parsing_XML/RepeatedSections/#sectioned-grouped-repeating","title":"Sectioned Grouped Repeating","text":"<pre><code>  &lt;root&gt;\n&lt;section&gt;\n&lt;!-- Necessary for processing the below events --&gt;\n&lt;sectionHeader&gt;header 1&lt;/sectionHeader&gt;\n\n&lt;ofInterest&gt; &lt;!-- Collect all of these --&gt;\n&lt;lotsOfInterestingSubTree&gt;\n&lt;value&gt;1&lt;/value&gt;\n&lt;/lotsOfInterestingSubTree&gt;\n&lt;/ofInterest&gt;\n&lt;ofInterest&gt; &lt;!-- Collect all of these --&gt;\n&lt;lotsOfInterestingSubTree&gt;\n&lt;value&gt;2&lt;/value&gt;\n&lt;/lotsOfInterestingSubTree&gt;\n&lt;/ofInterest&gt;\n&lt;ofInterest&gt; &lt;!-- Collect all of these --&gt;\n&lt;lotsOfInterestingSubTree&gt;\n&lt;value&gt;3&lt;/value&gt;\n&lt;/lotsOfInterestingSubTree&gt;\n&lt;/ofInterest&gt;\n&lt;/sectionHeader&gt;\n...\n    &lt;sectionHeader&gt;\n&lt;!-- Necessary for processing the below events --&gt;\n&lt;sectionHeader&gt;header 2&lt;/sectionHeader&gt;\n....\n  &lt;/root&gt;\n</code></pre>"},{"location":"Parsing_XML/RepeatedSections/#pull-parsing-resumableiteratees","title":"Pull Parsing ResumableIter'atees","text":"<p>ResumableIter is an Iteratee over E that instead of returning just a Done[R] returns Done[(R, NextResumableIter)].  The next ResumableIter stores the calculation up until the point of returning, allowing the calculation to be resumed.</p> <p>To process the above examples we make use of this and the onDone Iteratee.  This takes a list of ResumableIter and applies the input element to each of the Iteratees in that list, Done here returns both a list of the Iteratees which evaluate to Done for that input and (of course) the next continuation of onDone.</p> <p>A simple, and recommended, way to leverage onDone is with the foldOnDone function:</p> <pre><code>  val Headers = List(\"root\"l,\"section\"l,\"sectionHeader\"l)\nval OfInterest = List(\"root\"l,\"section\"l,\"ofInterest\"l)\n\nval ofInterestOnDone = onDone(List(onQNames(Headers), onQNames(OfInterest)))\n\nval total = foldOnDone(xml)( (0, 0), ofInterestOnDone ){ (t, qnamesMatch) =&gt;\nif (qnamesMatch.size == 0) {\nt // no matches\n} else {\n// only one at a time possible for xml matches (unless multiple identical onQNames are passed to onDone).\nassertEquals(1, qnamesMatch.size)\nval head = qnamesMatch.head\nassertTrue(\"Should have been defined\",head._2.isDefined)\n// we should never have more than one child in the parent\n// and thats us\nassertEquals(1, head._2.get.zipUp.children.size)\n\nval i = text(head._2.get).toInt\n// onQNames always returns the list as well as the XmlPath to allow matching against the input.\nif (head._1 eq Headers) {\nassertEquals(t._1, t._2)\n// get new section\n(i, 1)\n} else (t._1, i)\n}\n}\nassertEquals(total._1, total._2)\n</code></pre>"},{"location":"Serializing_%26_Transforming_XML/Folding/","title":"Folding Xml","text":"<p>Scales Xml provides a unique transformation option based on the premise of XmlPaths having document order.  It is therefore possible to navigate between two paths.  If we can do that then we can transform lists of paths within a same document by folding over them.</p> <p>Once a given path is modified it effectively refers to a new Xml tree, the trick is then to move the zipper to the next paths relative position in the old document.</p> <p>A number of transformations are available based on FoldOperation:</p> <ul> <li>AddAfter - ''add the nodes to the parent after the current path''</li> <li>AddBefore - ''add the nodes to the parent before the current path''</li> <li>AsIs - ''no-op''</li> <li>Remove - ''remove the current node''</li> <li>Replace - ''replace the current node''</li> <li>ReplaceWith - ''replace the current node with the results of another fold''</li> </ul> <p>AsIs and ReplaceWith deserve explanation before examples.  When performing transformations it is often useful to query or test against the resulting nodes, if the node should not be changed then AsIs() will make the fold a no-op.</p> <p>ReplaceWith effectively allows nested folds which an important part of the composing transformations.</p>"},{"location":"Serializing_%26_Transforming_XML/Folding/#pathfoldr-catchy-result-type","title":"PathFoldR - Catchy Result Type","text":"<p>The PathFoldR type is a (for Xml):</p> <pre><code>  XmlPath =&gt; Either[XmlPath, FoldError] // Either is the FoldR\n</code></pre> <p>Each foldPosition call is then resulting in either a new XmlPath or a reason as to why the transformation could not complete.  Valid reasons are:</p> <ul> <li>NoPaths - ''you didn't find any nodes with the path''</li> <li>NoSingleRoot - ''if the input nodes don't share a single root path how can we join them''</li> <li>RemovedRoot - ''you can't return changed nodes if the root element was deleted''</li> <li>AddedBeforeOrAfterRoot - ''you can't add nodes around the root element''</li> </ul>"},{"location":"Serializing_%26_Transforming_XML/Folding/#examples","title":"Examples","text":"<p>The below examples will use the following base xml and definitions:</p> <pre><code>  val ns = Namespace(\"test:uri\")\nval nsa = Namespace(\"test:uri:attribs\")\nval nsp = nsa.prefixed(\"pre\")\n\nval builder = ns(\"Elem\") /@ (nsa(\"pre\", \"attr1\") -&gt; \"val1\",\n\"attr2\" -&gt; \"val2\",\nnsp(\"attr3\") -&gt; \"val3\") /(\nns(\"Child\"),\n\"Mixed Content\",\nns(\"Child2\") /( ns(\"Subchild\") ~&gt; \"text\" )\n)\n</code></pre> <p>For a full set examples see the DslBuilderTests.scala.</p>"},{"location":"Serializing_%26_Transforming_XML/Folding/#adding-children","title":"Adding Children","text":"<p>The following example will add nodes around the existing nodes:</p> <pre><code>  val nodes = top(builder) \\* nodes.map(qname(_)) // Child, Child2\n\nval res = foldPositions( nodes  ){\ncase path if (!path.hasPreviousSibling) =&gt; AddBefore(\"start\"l)\ncase path if (!path.hasNextSibling) =&gt; AddAfter(\"end\"l)\n// will throw a MatchError if no _ see AsIs\n}\n\nasString(res.left.get.tree)\n</code></pre> <p>Will return the following XML (formatting added for readability):</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Elem xmlns=\"test:uri\" xmlns:pre=\"test:uri:attribs\" pre:attr3=\"val3\" attr2=\"val2\" pre:attr1=\"val1\"&gt;\n&lt;start xmlns=\"\"/&gt;\n&lt;Child/&gt;\nMixed Content\n  &lt;Child2&gt;\n&lt;Subchild&gt;text&lt;/Subchild&gt;\n&lt;/Child2&gt;\n&lt;end xmlns=\"\"/&gt;\n&lt;/Elem&gt;\n</code></pre>"},{"location":"Serializing_%26_Transforming_XML/Folding/#asis","title":"AsIs","text":"<p>In the [Adding_Children Adding Children] section we've left a possible match error, for example, if we choose not to act on the last child:</p> <pre><code>  // oops, surprising\nval res = foldPositions( nodes  ){\ncase path if (!path.hasPreviousSibling) =&gt; AddBefore(\"start\"l)\n// will throw a MatchError\n}\n</code></pre> <p>However, AsIs can be used to make sure we take normal actions if we have no match:</p> <pre><code>  val res = foldPositions( nodes  ){\ncase path if (!path.hasPreviousSibling) =&gt; AddBefore(\"start\"l)\ncase _ =&gt; AsIs\n}\n\nasString(res.left.get.tree)\n</code></pre> <p>Giving:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Elem xmlns=\"test:uri\" xmlns:pre=\"test:uri:attribs\" pre:attr3=\"val3\" attr2=\"val2\" pre:attr1=\"val1\"&gt;\n&lt;start xmlns=\"\"/&gt;\n&lt;Child/&gt;\nMixed Content\n  &lt;Child2&gt;\n&lt;Subchild&gt;text&lt;/Subchild&gt;\n&lt;/Child2&gt;\n&lt;/Elem&gt;\n</code></pre>"},{"location":"Serializing_%26_Transforming_XML/Folding/#removing-children","title":"Removing Children","text":"<p>In this example we'll remove the SubChild element:</p> <pre><code>  val nodes = top(builder) \\\\* ns(\"Subchild\") nodes.map(qname(_)) // Subchild\n\nval res = foldPositions( nodes  ){\n_ =&gt; Remove()\n}\n\nasString(res.left.get.tree)\n</code></pre> <p>Giving:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Elem xmlns=\"test:uri\" xmlns:pre=\"test:uri:attribs\" pre:attr3=\"val3\" attr2=\"val2\" pre:attr1=\"val1\"&gt;\n&lt;start xmlns=\"\"/&gt;\n&lt;Child/&gt;\nMixed Content\n  &lt;Child2/&gt;\n&lt;/Elem&gt;\n</code></pre>"},{"location":"Serializing_%26_Transforming_XML/Folding/#replacing-children","title":"Replacing Children","text":"<p>This example changes the text in Subchild:</p> <pre><code>  val nodes = top(builder). \\\\*(ns(\"Subchild\")). \\+.text\n\nnodes.map(string(_)) // Subchild\n\nval res = foldPositions( nodes  ){\n_ =&gt; Replace(\"another value\")\n}\n\nasString(res.left.get.tree)\n</code></pre> <p>yields:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Elem xmlns=\"test:uri\" xmlns:pre=\"test:uri:attribs\" pre:attr3=\"val3\" attr2=\"val2\" pre:attr1=\"val1\"&gt;\n&lt;start xmlns=\"\"/&gt;\n&lt;Child/&gt;\nMixed Content\n  &lt;Child2&gt;another value&lt;/Child2&gt;\n&lt;/Elem&gt;\n</code></pre>"},{"location":"Serializing_%26_Transforming_XML/Folding/#composing-transformations","title":"Composing Transformations","text":"<p>Transformations, like the rest of Scales, should also be composable.  It is possible to chain transformations allowing some to fail if they can't find matches - NoPaths - (| - Try The Next) to find matches or stopping at the earliest failure (&amp;_-_Fail_Early).</p> <p>In addition, they can be nested, performing transformations within transformations (ReplaceWith).</p>"},{"location":"Serializing_%26_Transforming_XML/Folding/#replacewith-nested","title":"ReplaceWith - Nested","text":"<p>ReplaceWith aims to mimic the nesting of matching templates in xslt (via call-template) whereas using the pattern matcher directly more closely resembles apply-templates.</p> <p>Using this replace as a basis:</p> <pre><code>  // for every child element add a text child that contains the qname of the elem\ndef addTextNodes( op : XmlPath ) =\nfoldPositions( op.\\* ) { p =&gt; Replace( p.tree / qname(p) ) }\n\nval allReplaced = addTextNodes( top(builder) )\n\nasString(allReplaced.left.get.tree)\n</code></pre> <p>yielding:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Elem xmlns=\"test:uri\" xmlns:pre=\"test:uri:attribs\" pre:attr3=\"val3\" attr2=\"val2\" pre:attr1=\"val1\"&gt;\n&lt;start xmlns=\"\"/&gt;\n&lt;Child&gt;Child&lt;/Child&gt;\nMixed Content\n  &lt;Child2&gt;\n&lt;Subchild&gt;text&lt;/Subchild&gt;\nChild2\n  &lt;/Child2&gt;\n&lt;/Elem&gt;\n</code></pre> <p>Now we can replace just the Subchild with:</p> <pre><code>  val nodes = top(builder). \\\\*(ns(\"Child2\"))\n\nval res = foldPositions( nodes  ){\n_ =&gt; ReplaceWith(x =&gt; addTextNodes(top(x.tree)))\n}\n\nasString(res.left.get.tree)\n</code></pre> <p>yielding:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Elem xmlns=\"test:uri\" xmlns:pre=\"test:uri:attribs\" pre:attr3=\"val3\" attr2=\"val2\" pre:attr1=\"val1\"&gt;\n&lt;Child/&gt;\nMixed Content\n  &lt;Child2&gt;\n&lt;Subchild&gt;textSubchild&lt;/Subchild&gt;\n&lt;/Child2&gt;\n&lt;/Elem&gt;\n</code></pre>"},{"location":"Serializing_%26_Transforming_XML/Folding/#-fail-early","title":"&amp; - Fail Early","text":"<p>The \"and\" chained transformation will stop when it hits any failure.</p> <p>Using the same base document as before:</p> <pre><code>  val wontFindAnyNodes = ( op : XmlPath ) =&gt;\nfoldPositions( op \\* ns(\"NotAChild\") ) { p =&gt; Replace( p.tree / qname(p) ) }\n\nval willFindANode = ( op : XmlPath ) =&gt;\nfoldPositions( op \\* ns(\"Child2\") ) { p =&gt; Replace( p.tree / qname(p) ) }\n\nval root = top(builder)\n\nval combined = wontFindAnyNodes &amp; willFindANode\n\nval noPaths = combined( root ) // Will be Right(NoPaths)\n</code></pre> <p>whereas:</p> <pre><code>  val alsoFindsANode = ( op : XmlPath ) =&gt;\nfoldPositions( op \\* ns(\"Child\") ) { p =&gt; Replace( p.tree / qname(p) ) }\n\nval andOk = willFindANode &amp; alsoFindsANode\n\nval result = andOk( root )\n\nasString(result.left.get.tree)  </code></pre> <p>yields:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Elem xmlns=\"test:uri\" xmlns:pre=\"test:uri:attribs\" pre:attr3=\"val3\" attr2=\"val2\" pre:attr1=\"val1\"&gt;\n&lt;Child&gt;Child&lt;/Child&gt;\nMixed Content\n  &lt;Child2&gt;\n&lt;Subchild&gt;text&lt;/Subchild&gt;\nChild2\n  &lt;/Child2&gt;\n&lt;/Elem&gt;\n</code></pre>"},{"location":"Serializing_%26_Transforming_XML/Folding/#-try-the-next","title":"| - Try The Next","text":"<p>The \"or\" chained transformation will try the next transformation if NoPaths is returned.  This allows safe chaining always passing the result through until the first failing transformation.</p> <p>Using the examples from &amp; above:</p> <pre><code>  val orWorks = wontFindAnyNodes | willFindANode\n\nval orResult = orWorks( root )\n\nasString(orResult.left.get.tree)  </code></pre> <p>yields:</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Elem xmlns=\"test:uri\" xmlns:pre=\"test:uri:attribs\" pre:attr3=\"val3\" attr2=\"val2\" pre:attr1=\"val1\"&gt;\n&lt;Child/&gt;\nMixed Content\n  &lt;Child2&gt;\n&lt;Subchild&gt;text&lt;/Subchild&gt;\nChild2\n  &lt;/Child2&gt;\n&lt;/Elem&gt;\n</code></pre>"},{"location":"Serializing_%26_Transforming_XML/SerializingIntro/","title":"An Introduction to Serializing Xml With Scales","text":"<p>Scales Xml delegates as much serializing as possible to the DOML3 LSSerializer framework.  There are a number of pain points, due to incompatibilities between jaxp implementations and jvm versions, that Scales smoothes out for the developer.</p> <p>The main aims with Scales serialisation are: </p> <ul> <li>A unified interface</li> <li>Correctness ''especially with a view to encoding issues''</li> </ul> <p>The unified interface is one main function:</p> <pre><code>  def serialize[T: SerializeableXml](pout: XmlOutput)(it: T) : Option[Throwable]\n</code></pre> <p>All XML types that can be serialized provide a SerializeableXml type class instance and the user supplies the XmlOutput object.  The users main interaction is through the SerializerData object allowing users to supply the output java.io.Writer and override both the encoding and xml version used.</p> <p>Typically one of the following functions will be used:</p> <ul> <li>writeTo( it, out )</li> <li>it writeTo out</li> <li>asString( it )</li> <li>itemAsString( xmlItem )</li> <li>printTree( it )</li> </ul> <p>The first two (writeTo) are the most general and the later three useful for debugging.</p> <p>No SerializeableXml type class instances are defined for XmlPaths as they can be either an XmlItem or Tree.  As such itemAsString exists for those times you really want to debug just the XmlItem.</p> <p>In all cases the xml is written out using the serialize function, which always writes out the xml declaration with the ''pout : XmlOutput'' parameter.  The more general writeTo approach will take the documents declaration unless specifically overridden.</p>"},{"location":"Serializing_%26_Transforming_XML/SerializingIntro/#writeto-writeto","title":"writeTo &amp; writeTo","text":"<p>The writeTo function: </p> <pre><code> def writeTo[T](it: T, output: Writer, version: Option[XmlVersion] = None, encoding: Option[Charset] = None)\n(implicit serializerFI: SerializerFactory, sxml: SerializeableXml[T])\n: Option[Throwable]\n</code></pre> <p>requires two parameters, the item to be serialized and the output Writer.  When the remaining two parameters are None (or simply left as default) the encoding and xml version are taken from the items document.</p> <p>To make life easier in the common case the WriteTo class (and implicits from ScalaXml._) allows a simpler:</p> <pre><code>  val testXml = loadXml(...)\nval str = asString(testXml)\n\nval out = new java.io.StringWriter()\ntestXml writeTo out\n\nassertEquals(str, out.toString)\n</code></pre>"},{"location":"Serializing_%26_Transforming_XML/SerializingIntro/#what-can-be-serialized","title":"What Can Be Serialized?","text":"<p>The following types can be serialized:</p> <ul> <li>XmlTree</li> <li>DslBuilder</li> <li>Doc</li> <li>Elem - an empty elem</li> <li>Iterator[PullType] - requires a full stream but works for all flavours of Pull</li> </ul> <p>With the itemAsString allowing simple debug output.</p> <p>If an object can be meaningfully written as Xml it is suggested to wrap streamSerializeable directly, converting your object into a stream as required.</p>"},{"location":"Serializing_%26_Transforming_XML/XSLT/","title":"TrAX &amp; XSLT Support","text":"<p>JAXP's TrAX API provides both serialisation and transformation to the jvm.  Scales leverages this api to allow xslt transformation and conversions to other DOMs.  Additionally Scales works around known compatibility issues with the Sun JVM and the Xerces implementations (with a nod to the Saxon for its extra support).</p> <p>Scales will attempt to, when the JVM/JAXP impl supports it, provide a StAXSource enabling transformation without intermediary objects.  This too, unfortunately, doesn't always correctly work across JAXP implementations, some versions ignoring prolog content (some even NPEing when any is present).</p> <p>As with most Scales JAXP integration the fall-back position of correctly serializing first is always available via the scales.traxSourceShouldSerialize property, when defined and true serialisation will occur before attempting a transformation.  When its not defined a best effort based on the transformer class name is used.</p> <p>The use of TrAX is generally simple enough not to require further wrapping, and Scales offers Folding for a more fitting transformation approach.</p> <p>Developers wishing pretty printing can also use TrAX to achieve this (as with a DOM object).</p>"},{"location":"Serializing_%26_Transforming_XML/XSLT/#simple-usage-example","title":"Simple Usage Example","text":"<p>Roundtripping with trax:</p> <pre><code>  val elem = Elem(\"trax\"l)\nval doc = Doc( elem / elem )\n\nimport javax.xml.transform._\nval trax = TransformerFactory.\nnewInstance.newTransformer\n\nval wr = new java.io.StringWriter()\nval str = new stream.StreamResult(wr)\ntrax.transform(doc, str)\nprintln(\"source only \" + wr.toString)\nval sr = ScalesResult()\ntrax.transform(doc, sr)\nprintln(\"roundtrip \" + asString(sr.doc))\n</code></pre> <p>yields:</p> <pre><code>source only &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;trax&gt;&lt;trax/&gt;&lt;/trax&gt;\nroundtrip &lt;?xml version=\"1.0\" encoding=\"UTF-16\"?&gt;&lt;trax&gt;&lt;trax/&gt;&lt;/trax&gt;\n</code></pre> <p>Note the utf-16 encoding, this was dictated by TrAX, and kept by Scales in the resulting Doc.</p>"},{"location":"XML_Model/Attributes/","title":"Attributes","text":"<p>XML Elements can contain attributes, these are made of a pair: QName and a string value.  Unlike Elements the QName of an Attribute must be either a fully qualified (PrefixedQName) or unqualified name (NoNamespaceQName).</p>"},{"location":"XML_Model/Attributes/#defining-an-attribute","title":"Defining an Attribute","text":""},{"location":"XML_Model/Attributes/#explicitly","title":"Explicitly","text":"<pre><code>  val ns = Namespace(\"uri:namespace\")\nval pre = ns.prefixed(\"pre\")\nval prefixedQName = pre(\"localName\")\nval nonamespaceQName = \"localName\"l\nval unprefixedQName = ns(\"localName\")\n\nval nonamespaceAttr = Attribute(nonamespaceQName, \"value\")\nval prefixedAttr = Attribute(prefixedQName, \"value\")\n\n// won't compile as Attributes can't have a namespace without a prefix\n//val unprefixedAttr = Attribute(unprefixedQName, \"value\")\n</code></pre>"},{"location":"XML_Model/Attributes/#implicitly","title":"Implicitly","text":"<pre><code>  // This can be used when defining elements or within the dsl\nval attr : Attribute = nonamespaceQName -&gt; \"value\"\n\n// won't compile\n// val noAttr : Attribute = unprefixedQName -&gt; \"value\"\n</code></pre>"},{"location":"XML_Model/Attributes/#equality","title":"Equality","text":"<p>The XML specifications require that no two attributes that share namespace and localName may be in the same element.  Attributes however must be testable for equality outside of this constraint:</p> <pre><code>  val attr2 : Attribute = nonamespaceQName -&gt; \"another value\"\n\nattr.name == attr2.name // true\n\nattr == attr2 // false, values are different\n\nval attr3 : Attribute = nonamespaceQName -&gt; \"another value\"\nattr3 == attr2 // true\n</code></pre>"},{"location":"XML_Model/Attributes/#within-an-elem","title":"Within an Elem","text":"<p>Scalaz Equal comes to the rescue again, we can separate the notion of attribute equality for simple comparisons and those of an Elem's requirements:</p> <pre><code>  attr3 === attr // true - we don't take the value into account  \n\nattr3 == attr // false - values are compared\n</code></pre>"},{"location":"XML_Model/Attributes/#attributes-listset","title":"Attributes ListSet","text":"<p>The Scales Utils class ListSet compares using the notion of Equiv equivalence (see Equiv and Equal for more details).  To make things easier for developers not using the DSL, Scales adds the Attribs() constructor (which ensures the appropriate Equal and Equiv type classes are always present):</p> <pre><code>  val attributes = Attribs(attr, prefixedQName -&gt; \"yet another value\")\n</code></pre>"},{"location":"XML_Model/Attributes/#testing-against-qnames-or-namespaces","title":"Testing Against QNames or Namespaces","text":"<p>QNameMatcher and Namespace matcher provide simple matching logic that can simplify certain types of pattern matches, just like Scala Regex - see Testing For QNames for examples.</p>"},{"location":"XML_Model/Elem/","title":"Elem","text":""},{"location":"XML_Model/Elem/#xml-elements","title":"XML Elements","text":"<p>Elements in XML are markup that scopes other parts of the document, typically this scoping is seen as a containment relationship in XML object models.  Classical DOM follows this approach as does Scala XML.</p>"},{"location":"XML_Model/Elem/#declaring","title":"Declaring","text":"<pre><code>  val ns = Namespace(\"uri:namespace\")\nval pre = ns.prefixed(\"pre\")\nval name = pre(\"localName\")\n\nval attr = pre(\"attribute\")\n\nval elem = Elem(name, Attribs(\"a\" -&gt; \"non namespaced\", attr -&gt; \"prefixed attribute\"))\n</code></pre> <p>See attributes for an explanation of how -&gt; works.</p>"},{"location":"XML_Model/Elem/#qname-and-namespace-correctness","title":"QName And Namespace Correctness","text":"<p>Elements also contain both declarations of namespaces, introducing new prefixes or default namespaces, and Attributes. Elements are declared with a given QName, which can also be a non-prefixed but namespaced.</p> <pre><code>  &lt;!-- this element name has no prefix but a namespace --&gt;\n&lt;elem xmlns=\"uri:test\"&gt; &lt;!-- this element name also has no prefix but a namespace --&gt;\n&lt;child&gt;\n&lt;!-- this element name has no namespace and declares \n           that all child elements, by default, have no namespace --&gt;\n&lt;grandchild xmlns=\"\"&gt; .....\n    &lt;!-- this element contains an attribute (without a namespace) \n\t but has its name with a namespace --&gt;\n&lt;child attribute=\"value\"&gt;\n....\n    &lt;!-- this element declares a new \n    \t namespace and prefix mapping. --&gt;\n&lt;child xmlns:pre=\"uri:anotherNamespace\"&gt;\n&lt;!-- this elements name is prefixed and within a namespace \n\t   but the element declares a default namespace. --&gt;\n&lt;pre:grandchild xmlns=\"\"&gt;\n</code></pre> <p>As can be seen there are a number of complex combinations with namespaces and attributes that are possible and that the attribute mechanism itself is used to declare namespaces.</p> <p>When supporting XML 1.0 only it can also be seen that storing the namespaces declared on an element is not necessary if all the QNames are typed.  XML 1.1, however, allows the removal of a namespace prefix definition and requires that this information is stored.  If nothing else its quite helpful to be able to define where a namespace prefix declaration should appear.</p> <p>Scales, however, does not conflate the ideas of namespace declaration, attributes or the qualified names of elements.</p>"},{"location":"XML_Model/Elem/#elems-are-reusable","title":"Elems Are Reusable","text":"<p>Scales Elem contains the QName, Attributes and optionally prefix declarations.  They do not have any notion of containment and as such are re-usable not only within a document but across documents.  Servers processing high volumes of related data can of course benefit from the reduced allocation costs, but the code can also benefit.</p> <p>Declaring an Elem once and simply including it within a tree definition is not only made possible but encouraged:</p> <pre><code>  val unprefixedQName = \"uri:namespace\" :: \"localName\"\nval elem = Elem(unprefixedQName)\nval root = &lt;(elem) /( elem, elem, elem, elem /( elem )\n)\nasString(root)\n</code></pre> <p>gives (''formatting added to match root's above definition''):</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;localName xmlns=\"uri:namespace\"&gt;\n&lt;localName/&gt;&lt;localName/&gt;&lt;localName/&gt;\n&lt;localName&gt;\n&lt;localName/&gt;\n&lt;/localName&gt;\n&lt;/localName&gt;\n</code></pre>"},{"location":"XML_Model/Elem/#runtime-validation-checks","title":"Runtime Validation Checks","text":"<p>As Elem is created with a QName it is subject to all of QNames correctness and runtime checks.</p> <p>In addition, Scales enforces that you cannot create an Elem with a prefix of xmlns or xml.</p>"},{"location":"XML_Model/OptionalDsl/","title":"Optional Xml DSL","text":"<p>The [XmlDsl.html Xml DSL] provides a simple way to create XML trees via a flexible builder approach.  The Optional Xml DSL provides a similar approach to fully optionl trees, where no empty nodes should be present.  </p> <p>Given the following xml:</p> <pre><code>  &lt;root xmlns=\"uri:test\"&gt;\n&lt;optional&gt;some possible text&lt;/optional&gt;\n&lt;/root&gt;\n</code></pre> <p>we may like to remove optional if the \"some possible text\" was not defined (for example against a minoccurs 0 element).</p> <p>The Optional DSL fully integrates within the Xml DSL itself, allowing easily defined optional subtrees, but uses a different notation to let you know at a glance you are dealing with the Optional DSL:</p> <pre><code>  val ns = Namespace(\"uri:test\") val root = ns(\"root\")\nval optional = ns(\"optional\")\n\ndef someOptionalText: Option[String] = ???\n\n// optional is converted into an instance of OptionalDslBuilder allowing ?~&gt; to be called\nval optionalxml = root /( optional ?~&gt; someOptionalText )\n</code></pre> <p>If someOptionalText returns Some(\"a value\") optionalxml will serialize to</p> <pre><code>  &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;root xmlns=\"uri:test\"&gt;&lt;optional&gt;a value&lt;/optional&gt;&lt;/root&gt;\n</code></pre> <p>however returning None will collapse the optional element as well as the text (this is in contrast to ~&gt; Option[String] in the normal Xml DSL which leaves the optional element present):</p> <pre><code>  &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;root xmlns=\"uri:test\"/&gt;\n</code></pre> <p>The api for the Optional DSL can be found here.</p>"},{"location":"XML_Model/OptionalDsl/#cascading-optionals","title":"Cascading Optionals","text":"<p>The Optional DSL cascades so the following xml:</p> <pre><code>  val deepNones = ?&lt;(\"Alocal\"l).?/( ?&lt;(\"another\"l) ?/( (\"lowerstill\"l) ?~&gt; None ),\n?&lt;(\"yetan\"l) ?~&gt; None\n).addNonEmpty((\"ShouldNotGetAdded\"l))\n\nval result = deepNones.toOptionalTree\n</code></pre> <p>will have result.isEmpty == true.</p> <p>Serializing OptionalDsls doesn't make much sense without at least one outer wrapping node, as such no SerializeableXml type class instance is provided.</p> <p>The addNonEmpty method above allows adding child nodes directly, but filters out any empty trees (no child nodes or attributes).  It does not, however, perform deep cascading, so prefer OptionalDslBuilder instances where possible.</p> <p>The \"?&lt;\" constructor is the Optional DSL counterpart to the Xml DSLs \"&lt;\" and acts a visual marker.</p>"},{"location":"XML_Model/QNames/","title":"QNames","text":"<p>[http://www.w3.org/TR/2009/REC-xml-names-20091208/#NT-NCName The namespaces spec] introduced namespaces into XML, giving the three following possible types of qualified names:</p> <ol> <li>Fully Qualified (local name, prefix and namespace)</li> <li>No namespace (local name only xmlns=\"\")</li> <li>Namespaced (local name and namespace - xmlns=\"a new default scoped namespace\")</li> </ol> <p>This can be seen modelled in the JAXP QName class, or as the QName ADT in Scales.  The namespaces spec introduced the letter \":\" as a separator of prefix and local name, as such its use is forbidden in QName prefixes or localNames (runtime check).</p>"},{"location":"XML_Model/QNames/#creating-qnames","title":"Creating QNames","text":""},{"location":"XML_Model/QNames/#directly","title":"Directly","text":"<pre><code>  val ns = Namespace(\"uri:namespace\")\nval pre = ns.prefixed(\"pre\")\nval prefixed = PrefixedQName( \"local\", pre )\n\n// same as above\nval prefixed2 = pre(\"local\")\n\n// without a prefix - only for Elems\nval namespaced = ns(\"local\")\n\nval noNamespace = NoNamespaceQName(\"local\")\n\nval prefixedDirect = ns.prefixed(\"pre2\",\"local\")\n</code></pre>"},{"location":"XML_Model/QNames/#implicits","title":"Implicits","text":"<pre><code>  // implicitly make it, allowing for \\*(\"localNameOnly\") XPath 1.0 syntax\nval localOnly : NoNamespaceQName = \"local\"\n\n// \"directly\" declaring it local with .l\nval noNamespace = \"local\"l\n\nval unprefixed = \"test:namespace\"::\"local\"\n</code></pre>"},{"location":"XML_Model/QNames/#namespaces-scope","title":"Namespaces &amp; Scope","text":"<p>Namespaces are scoped according to the nesting of XML elements.  If the root declares a default namespace it applies for all of the XML child elements unless overridden by introducing a new scoped default namespace.</p> <p>This scoping does not apply to attributes, they are either fully qualified or have namespace xmlns=\"\".  Namespaces are in XML 1.0 URIs and in XML 1.1 IRIs.</p> <p>Namespace prefixes also have a different binding relationship in XML 1.1 documents, where xmlns:pre=\"\" is actually legal (albeit very confusing) and unbinds the \"pre\" prefix.  This makes it invalid to use the \"pre\" prefix again (taken from the 1.1 namespaces spec):</p> <pre><code>&lt;?xml version=\"1.1\"?&gt;\n&lt;x xmlns:n1=\"http://www.w3.org\"&gt;\n&lt;n1:a/&gt;               &lt;!-- legal; the prefix n1 is bound to http://www.w3.org --&gt;\n&lt;x xmlns:n1=\"\"&gt;\n&lt;n1:a/&gt;           &lt;!-- illegal; the prefix n1 is not bound here --&gt;\n&lt;x xmlns:n1=\"http://www.w3.org\"&gt;\n&lt;n1:a/&gt;       &lt;!-- legal; the prefix n1 is bound again --&gt;\n&lt;/x&gt;\n&lt;/x&gt;\n&lt;/x&gt;\n</code></pre> <p>Scales attempts to provide validation of the names via the version, but this is more than a little edge case filled.  Other libraries (XOM for example) have chosen to not support XML 1.1s use at all.</p> <p>See XML Version Support for more details.</p>"},{"location":"XML_Model/QNames/#namespaces-in-scales","title":"Namespaces in Scales","text":"<p>Namespaces are directly modelled as a type in Scales and are used to create QNames.  Namespaces are created simply by</p> <pre><code>  // a Namespace\nval ns = Namespace(\"test:uri\")\n// a PrefixedNamespace\nval p = ns.prefixed(\"p\")\n\n// this QName is fully qualified\nval qname = p(\"localname\")\n</code></pre> <p>PrefixedNamespaces are required to create a PrefixedQName but can also lead to simpler looking code.  In addition, they can be used to declare namespace mappings on a particular level of a tree (attached to Elem - which can reduce re-use), the XML 1.1 example above requires this approach of declaring the mappings.</p>"},{"location":"XML_Model/QNames/#qnames-in-scales-let-the-compiler-help-us","title":"QNames in Scales - Let the compiler help us","text":"<p>Scales enforces the use of QNames throughout its api.  Attributes can '''only''' be created with either a NoNamespaceQName or a PrefixedQName.  Elements also can use UnprefixedQNames:</p> <pre><code>    val ns = Namespace(\"uri:namespace\")\n    val pre = ns.prefixed(\"pre\")\n    \n    val unprefixedQName = ns(\"localName\")\n    val prefixedQName = pre(\"localName\")\n    // l is a NoNamespaceQName wrapper\n    val nonamespaceQName = \"localName\"l\n\n    val uelem = Elem(unprefixedQName)\n    \n    // implicitly converted, nonamespaceQName is valid for an attribute\n    val nonamespaceAQN : AttributeQName = \n      nonamespaceQName\n\n    // won't compile as unprefixed but namespaced QNames are not valid for an attribute\n    //val unprefixedAQN  : AttributeQName = \n    //  unprefixedQName\n\n    val root = \n      &lt;(uelem) /@(nonamespaceAQN -&gt; \"nv\",\n\t\t  prefixedQName -&gt; \"pv\") /(\n\tprefixedQName, // these implicitly create an XmlTree with this QName\n\tnonamespaceQName \n      )\n</code></pre>"},{"location":"XML_Model/QNames/#runtime-validation","title":"Runtime Validation","text":"<p>Whilst the compiler can help us with correctness on types, we sacrifice a usable api if we force other content checks into the type system.  For example we could model QName.apply functions to return an Either (or Validation) and force combination of all Elem related data, but this would distract from the api (especially considering that incorrect XML is only likely to come from the developer - the parser won't let it through otherwise).</p> <p>Scales QNames and Namespaces check for correct local name and prefix content at runtime based on the compile time scoped XmlVersion.  This still implies no object will ever get created with incorrect data, but forces these checks into throwing exceptions (or make the user suffer with the api that follows).</p> <p>Valid characters for a given xml version are checked by Xerces XML Char utilities with the addition of a simple \":\" check from Scales.  Developers may not create a Namespace with \"\" unless using Xml11.  Declaring PrefixedNamespaces with prefix \"xmlns\" or \"xml\" must match their predefined uris.</p> <p>NB: I've not given up on attempting this completely</p>"},{"location":"XML_Model/QNames/#equality","title":"Equality","text":"<p>Namespaces are equal only when their uri is equal, but PrefixedNamespaces also take the prefix into account.</p> <p>QNames use both namespace + local name to test for equality:</p> <pre><code>  // using the above definitions \nnoNamespace == unprefixed // false\n\nval unprefixed2 = \"fred:uri\" :: \"local\"\n\nunprefixed2 == unprefixed // false\n\n// =:= is a seperate method that acts as == but is typed on QNames\nprefixed =:= prefixed2 // true\n\nval prefixedl2 = pre(\"local2\")\nprefixed =:= prefixedl2 // false\n\nprefixedDirect == prefixed // true\n</code></pre> <p>For PrefixedQNames its also possible to take the prefix itself into consideration (although not recommended):</p> <pre><code>  prefixedDirect =:= prefixed // true\n\nprefixedDirect === prefixed // false\n</code></pre>"},{"location":"XML_Model/QNames/#scalaz-equal-and-scales-equiv","title":"Scalaz Equal and Scales Equiv","text":"<p>A Scalaz Equal typeclass is defined allowing (but shadowed by QName for its default):</p> <pre><code>  import scalaz._\nimport Scalaz._\n\nimplicitly[Equal[QName]].equal(prefixedDirect, prefixed) // true\n</code></pre> <p>Equiv is a helper class from Derek Williams that allows defining conversions to types that have a provided Scalaz Equal type class instance.  This is used by ListSet to allow removal of Attributes by their QName (via =:=).</p> <pre><code>  import scalaz._\nimport Scalaz._\n\n// the below is provided by the scales.utils.equivalent\nimplicitly[Equiv[QName]].apply(prefixedDirect, prefixed) // true\n\nequivalent( prefixedDirect, prefixed ) // true\n\n// PrefixedQName and NoNamespaceQName can be \"converted\" to QName\nequivalent( prefixedDirect, localOnly) // false\n</code></pre>"},{"location":"XML_Model/QNames/#testing-for-qnames","title":"Testing For QNames","text":"<p>Equality and Extractors can cover most usage scenarios but sometimes you want to test and extract in one go - just like Scala's regex support.</p> <p>As part of the Xml DSL Scales provides both QName and Namespace Matchers.  Starting with the following definitions we'll look at how to use these Matchers:</p> <pre><code>  val ns = Namespace(\"uri:namespace\")\nval name = ns.prefixed(\"pre\",\"localName\")\n\nval elem = Elem(name)\nval attrib = Attribute(name, \"val\")\n</code></pre> <p>QNameMatcher allows you to test for whether an Attribute or an Elem is defined by a given QName (via =:=, namespace and local name only are compared):</p> <pre><code>  val NamedMatcher = name.matcher // .m is a short cut\n\nelem match {\ncase NamedMatcher(e) =&gt; println(\"Matched element \" + asString(e))\ncase _ =&gt; error(\"oops\")\n}\n\nattrib match {\ncase NamedMatcher(a) =&gt; println(\"Matched attribute \" + a)\ncase _ =&gt; error(\"oops\")\n}\n</code></pre> <p>NamespaceMatcher simply checks for the Attribute or an Elem being part of a Namespace:</p> <pre><code>  val NamespaceMatcher = ns.m // short for matcher\nelem match {\ncase NamespaceMatcher(e) =&gt; println(\"Matched element \" + asString(e))\ncase _ =&gt; error(\"oops\")\n}\n\nattrib match {\ncase NamespaceMatcher(a) =&gt; println(\"Matched attribute \" + a)\ncase _ =&gt; error(\"oops\")\n}\n</code></pre>"},{"location":"XML_Model/QNames/#serializing-qnames","title":"Serializing QNames","text":"<p>QNames for elements and attributes are considered markup, and depending on both the encoding and Xml Version will throw an InvalidCharacterInMarkup exception with the relevant QName part that caused the issue.</p>"},{"location":"XML_Model/XmlDsl/","title":"Xml DSL and Trees","text":"<p>XML DOMs traditionally create trees by each element \"owning\" its children.  Scales eschews this model, instead using trees to model the containment, allowing re-use for all of the Scales model.</p> <p>To simplify both creating and basic manipulation of trees Scales provides a DSL that closely resembles the structure of XML.  The point of focus in the tree (or the depth) is controlled by nesting of the arguments.  The implementing class is [./doc/scales/xml/dsl/DslBuilder.html DslBuilder]</p> <p>The following example is a quick introduction into how to create trees (also used within the XPath guide):</p> <pre><code>  val ns = Namespace(\"test:uri\")\nval nsa = Namespace(\"test:uri:attribs\")\nval nsp = nsa.prefixed(\"pre\")\n\nval builder = ns(\"Elem\") /@ (nsa(\"pre\", \"attr1\") -&gt; \"val1\",\n\"attr2\" -&gt; \"val2\",\nnsp(\"attr3\") -&gt; \"val3\") /(\nns(\"Child\"),\n\"Mixed Content\",\nns(\"Child2\") /( ns(\"Subchild\") ~&gt; \"text\" )\n)\n</code></pre>"},{"location":"XML_Model/XmlDsl/#tour-of-the-dsl","title":"Tour of the DSL","text":"<p>The tour will use the following definitions:</p> <pre><code>  val ns = Namespace(\"uri:test\") val elem = ns(\"Elem\")\nval child = ns(\"Child\")\nval childl = \"Child\"l\nval root = ns(\"Root\")\nval child1 = ns(\"Child1\")\nval child2 = ns(\"Child2\")\nval child3 = ns(\"Child3\")\nval fred = ns(\"fred\")\n</code></pre>"},{"location":"XML_Model/XmlDsl/#creating-a-tree","title":"Creating a Tree","text":"<p>To start a tree simply use a qname or elem followed by a DSL operator:</p> <pre><code>  val dsl = elem / child\n\n// &lt;Elem xmlns=\"uri:test\"&gt;&lt;Child/&gt;&lt;/Elem&gt;\nasString(dsl) </code></pre> <p>or for visual distinction use the &lt;( ) function</p> <pre><code>  val dsl2 = &lt;(elem) / child\n</code></pre>"},{"location":"XML_Model/XmlDsl/#adding-to-the-tree","title":"Adding To The Tree","text":"<p>To add a subelement use:</p> <pre><code>  // &lt;Elem xmlns=\"uri:test\"&gt;&lt;Child/&gt;&lt;Child2/&gt;&lt;Child3/&gt;&lt;/Elem&gt;\nval dsl3 = dsl2 /( child2, child3)\n</code></pre> <p>The tree can be freely nested and, instead of a sequence of subtrees, a by-name version with taking an Iterable allows you to call other functions to provide the sub-trees. </p>"},{"location":"XML_Model/XmlDsl/#adding-an-attribute","title":"Adding an Attribute","text":"<pre><code>  // &lt;Elem xmlns=\"uri:test\" attr=\"fred\"&gt;&lt;Child/&gt;&lt;Child2/&gt;&lt;Child3/&gt;&lt;/Elem&gt;\nval dsl4 = dsl3 /@( \"attr\" -&gt; \"fred\" )\n</code></pre>"},{"location":"XML_Model/XmlDsl/#setting-text","title":"Setting Text","text":"<p>As we often set a single string for a given subtree the DSL provides a helpful feature to replace all child nodes with a single text node.</p> <pre><code>  // &lt;Elem xmlns=\"uri:test\" attr=\"fred\"&gt;a string&lt;/Elem&gt;\nval dsl5 = dsl4 ~&gt; \"a string\"\n</code></pre> <p>This can, of course, be nested:</p> <pre><code>  // res14: String = &lt;Elem xmlns=\"uri:test\" attr=\"fred\"&gt;&lt;Child/&gt;\n// &lt;Child2/&gt;&lt;Child3/&gt;&lt;fred&gt;fred's text&lt;/fred&gt;&lt;/Elem&gt;\nval dsl6 = dsl4 /( fred ~&gt; \"fred's text\" )\n</code></pre>"},{"location":"XML_Model/XmlDsl/#removing-children","title":"Removing Children","text":"<p>Any child whose QName matches (namespace and localname =:=) will be removed via:</p> <pre><code>  // &lt;Elem xmlns=\"uri:test\" attr=\"fred\"&gt;&lt;Child2/&gt;&lt;Child3/&gt;&lt;fred&gt;fred's text&lt;/fred&gt;&lt;Child xmlns=\"\"/&gt;&lt;/Elem&gt;\nval dsl7 = (dsl6 -/ child) / childl\n</code></pre> <p>Note that due to infix limitations of Scala that the following won't compile:</p> <pre><code>  // won't compile as its an even number of terms\nval dsl7 = dsl6 -/ child / childl\n</code></pre> <p>If in doubt use brackets or dot accessors to be specific.</p>"},{"location":"XML_Model/XmlDsl/#removing-attributes","title":"Removing Attributes","text":"<p>Similar to removing Elems QName and a - do the job:</p> <pre><code>  // &lt;Elem xmlns=\"uri:test\"&gt;&lt;Child2/&gt;&lt;Child3/&gt;&lt;fred&gt;fred's text&lt;/fred&gt;&lt;Child xmlns=\"\"/&gt;&lt;/Elem&gt;\nval dsl8 = dsl7 -/@ \"attr\"\n</code></pre>"},{"location":"XML_Model/XmlDsl/#optional-xml","title":"Optional XML","text":"<p>When using the DSL to template XML its often necessary to model optional content.  This can be expressed via direct use of Option for an attribute, child or text directly:</p> <pre><code>  def template(optionalText : Option[String) =\nns(\"Elem\") ~&gt; optionalText\n\nval hasTextChild = template(Some(\"text\"))\nval hasNoChildren = template(None)\n</code></pre> <p>As hasNoChildren demonstrates, when using None, there will be no child added.  Using \"\" instead, would add an empty Child, whilst semantically identical upon serialization it changes the meaning of the in-memory DOM itself.</p> <p>The Attribute and child variants function in the same way, but for some usages a fully cascading solution may be required.  If the elem itself should also not be added when there are no children present then the [OptionalDsl.html Optional DSL] should be used.</p>"},{"location":"XML_Model/XmlDsl/#folding-within-the-dsl","title":"Folding Within The DSL","text":"<p>The XPath fold facility is also present directly from the DSL, letting you stay within the tree building and manipulate at the same time with the full power of the DSL.</p> <p>The DSL provides three fold functions, fold - returning an Either (as per the normal fold but wrapped with DslBuilder), fold_! (throws upon an error) and fold_?.</p> <p>The fold_? function is perhaps the most commonly useful, and returns \"this\" if no folds took place (NoPaths), but throws if an error was found.</p> <p>In each case the parameters are XmlPath =&gt; XPath (to allow selection) and the folder (what should we do with the selection) and is used thusly:</p> <pre><code>  // remove all ChildX elements regardless of namespace yielding:\n// &lt;Elem xmlns=\"uri:test\"&gt;&lt;fred&gt;fred's text&lt;/fred&gt;&lt;/Elem&gt;\nval dsl9 = dsl8.fold_?( _.\\*( x =&gt; localName(x).startsWith(\"Child\"))) {\np =&gt; Remove()\n}\n</code></pre> <p>See XPath Folds for more information and how to use it for transformations.</p>"},{"location":"XML_Model/XmlItem/","title":"XmlItem","text":"<p>Scales represents non Elem data as XmlItem, this includes Text, CData, PI (processing instructions) and Comment.  They share the base trait XmlItem which provides one member:</p> <pre><code>  val value : String\n</code></pre> <p>With PI also adding:</p> <pre><code>  val target : String\n</code></pre>"},{"location":"XML_Model/XmlItem/#declaring","title":"Declaring","text":"<pre><code>  val text = Text(\"A text value\")\nval cdata = CData(\"Some cdata\")\nval comment = Comment(\"A comment\")\nval pi = PI(\"Target id\",\"instruction value\")\n</code></pre>"},{"location":"XML_Model/XmlItem/#xmlitems-are-reusable","title":"XmlItems Are Reusable","text":"<p>XmlItems, as with the rest of Scales - having separated data from structure, have no notion of ownership.</p> <p>This implies they can be re-used both within and across documents.  This follows with Elems and Trees themselves allowing whole sections of XML to be re-used.</p>"},{"location":"XML_Model/XmlItem/#runtime-correctness-checks","title":"Runtime Correctness Checks","text":"<p>There are a number of simple rules for XmlItems, driven by the spec:</p> <ol> <li>Comments cannot contain the text \"\u2013\"</li> <li>CData cannot contain \"]]&gt;\"</li> <li>PIs cannot contain \"?&gt;\" in the value or target</li> <li>PIs target when lower cased cannot start with \"xml\"</li> </ol>"},{"location":"XML_Model/XmlItem/#serializing-xmlitems","title":"Serializing XmlItems","text":"<p>Text, Comments and PI may contain character references and can be correctly serialized regardless of the encoding or Xml Version used.</p>"},{"location":"XML_Model/XmlItem/#serializing-cdata","title":"Serializing CData","text":"<p>CData is problematic to serialise due to:</p> <ul> <li>JAXP differences (Xerces/Xalan, Saxon and Sun jdk) all behave differently with regards to CData serialisation</li> <li>CData itself can be encoded but not &lt; and &amp;, doing so changes the CData.</li> <li>CData, similar to QNames, cannot be encoded via character references</li> </ul> <p>The problems here should warn the user not use CData at all, as per ERH it does not add anything.  It is only provided in Scales to allow documents to be passed through as is (e.g. content based routing).</p> <p>Scales does its best to work around such issues including, forbidding CData splits, custom serializing (jre will write no end part to cdata) and verifying that the data can be written at all in the documents encoding.</p>"},{"location":"XML_Model/XmlVersionSupport/","title":"Scales XML Version Support","text":"<p>There are two versions of XML, 1.0 and 1.1, with 1.0 being most commonly used.</p> <p>1.1 parsers can parse 1.0 xml, but not the other way around, which adds for another source of potential differences in user experience.</p>"},{"location":"XML_Model/XmlVersionSupport/#differences-between-10-and-11","title":"Differences Between 1.0 and 1.1","text":"<p>There are four main differences:</p> <ol> <li>Unicode markup - elements can have names in Kanji</li> <li>Certain whitespace is (dis)allowed</li> <li>Namespaces can be \"unbound\" from their prefixes</li> <li>Namespaces are IRIs not URIs</li> </ol> <p>These differences make 1.1 support difficult to pleasantly achieve and, in order to keep a uniform interface, forces some correctness checks into the runtime.</p>"},{"location":"XML_Model/XmlVersionSupport/#how-does-scales-allow-both-versions","title":"How Does Scales Allow Both Versions ?","text":"<p>Scales takes a pragmatic approach to supporting both versions via using implicits, with the defaultVersion being 1.0.  Override the implicit to provide scoped XML 1.1 support:</p> <pre><code>  // scope here is Xml10\n{\nimplicit val defaultVersion = Xml11 // scope here is Xml11\nval ns = Namespace(\"http://www.w3.org\")\nval pre = ns.prefixed(\"n1\")\nval disabled = Elem(\"x\"l, Namespace(\"\").prefixed(\"n1\"))\nval a = Elem(pre(\"a\"))\nval x = Elem(\"x\"l, pre)\n}\n</code></pre> <p>All of the above example namespaces, local names and prefixes are then validated for correctness at runtime.  The above example with Xml10 would throw as \"\" is not a valid namespace for XML 1.0 (and is only used in XML 1.1 for unbinding namespace prefixes).</p>"},{"location":"XML_Model/XmlVersionSupport/#in-parser-we-trust-users-we-protect","title":"In Parser We Trust - Users We Protect","text":"<p>Runtime checks for correctness are redundant if the model is created via a parser.  The parser already checks the validity (users may choose to override the settings at the factory level).</p> <p>However, for general usage it's helpful for the library to safeguard us against mistakes.  Scales emphasis on correctness continues here as well.</p> <p>The implicit FromParser is used by Scales to provide this runtime check, and the QNameCharUtils functions provide the helpers for a given version (via Xerces XMLChar and XML11Char.</p>"},{"location":"XML_Model/XmlVersionSupport/#runtime-xmlversion-qname-related-correctness","title":"Runtime XmlVersion QName Related Correctness","text":"<p>The implicitly scoped version dictates what runtime checks are applied.  In particular the namespace, local name and prefix are all validated at runtime for their content.  This is true for both Attribute and Elem QNames.</p> <p>Serializing is also, of course, affected by the XML version.  The document serialisation itself then requires checking the compatibility of QNames.  The rule here is simply if it's an Xml11 QName only (all parts are correct) and the document version is Xml10 its an error.</p>"}]}